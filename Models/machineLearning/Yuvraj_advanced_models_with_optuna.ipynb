{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047025ab",
   "metadata": {},
   "source": [
    "# Advanced ML Models with Optuna Tuning\n",
    "Yuvraj Grover\n",
    "\n",
    "This notebook implements and tunes advanced ML models using Optuna:\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- CatBoost\n",
    "- MLP (optional revisit)\n",
    "\n",
    "Each model will be trained and tuned using Optuna and evaluated on the diabetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f27fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f497846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>gender</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>...</th>\n",
       "      <th>mb_readmitted_no_ct</th>\n",
       "      <th>mb_num_lab_procedures_ct</th>\n",
       "      <th>mb_num_procedures_ct</th>\n",
       "      <th>mb_num_medications_ct</th>\n",
       "      <th>mb_number_outpatient_ct</th>\n",
       "      <th>mb_number_emergency_ct</th>\n",
       "      <th>mb_number_inpatient_ct</th>\n",
       "      <th>mb_number_diagnoses_ct</th>\n",
       "      <th>age_encoded</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35754</td>\n",
       "      <td>82637451</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55842</td>\n",
       "      <td>84259809</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr  gender  time_in_hospital  num_lab_procedures  \\\n",
       "2         64410     86047875  Female                 2                  11   \n",
       "3        500364     82442376    Male                 2                  44   \n",
       "4         16680     42519267    Male                 1                  51   \n",
       "5         35754     82637451    Male                 3                  31   \n",
       "6         55842     84259809    Male                 4                  70   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "2               5               13                  2                 0   \n",
       "3               1               16                  0                 0   \n",
       "4               0                8                  0                 0   \n",
       "5               6               16                  0                 0   \n",
       "6               1               21                  0                 0   \n",
       "\n",
       "   number_inpatient  ...  mb_readmitted_no_ct mb_num_lab_procedures_ct  \\\n",
       "2                 1  ...                    1                       11   \n",
       "3                 0  ...                    1                       44   \n",
       "4                 0  ...                    1                       51   \n",
       "5                 0  ...                    0                       31   \n",
       "6                 0  ...                    1                       70   \n",
       "\n",
       "  mb_num_procedures_ct mb_num_medications_ct mb_number_outpatient_ct  \\\n",
       "2                    5                    13                       2   \n",
       "3                    1                    16                       0   \n",
       "4                    0                     8                       0   \n",
       "5                    6                    16                       0   \n",
       "6                    1                    21                       0   \n",
       "\n",
       "  mb_number_emergency_ct mb_number_inpatient_ct mb_number_diagnoses_ct  \\\n",
       "2                      0                      1                      6   \n",
       "3                      0                      0                      7   \n",
       "4                      0                      0                      5   \n",
       "5                      0                      0                      9   \n",
       "6                      0                      0                      7   \n",
       "\n",
       "   age_encoded  dummy  \n",
       "2          1.0      1  \n",
       "3          2.0      1  \n",
       "4          3.0      1  \n",
       "5          4.0      1  \n",
       "6          5.0      1  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "df = pd.read_pickle('../../dataPreprocessing/medical_data.pkl')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5170af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "# Drop Gurmat's excluded columns + target column\n",
    "# Drop known leaky features\n",
    "# List of leaky features to drop\n",
    "leaky_features = [\n",
    "    'mb_readmitted_gt30_ct', 'mb_readmitted_no_ct', 'mb_readmitted_lt30_ct',\n",
    "    'distinct_diag_count', 'encounter_ct', 'mb_number_diagnoses_ct',\n",
    "    'mb_num_lab_procedures_ct', 'mb_num_medications_ct', 'mb_time_in_hospital',\n",
    "    'mb_admission_grp_1_ct', 'mb_discharge_grp_1_ct', 'mb_number_inpatient_ct'\n",
    "]\n",
    "\n",
    "X = df.drop(columns=leaky_features + ['readmitted', 'readmitted_ind'], errors='ignore')\n",
    "y = df['readmitted_ind']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_encoded = X.copy()\n",
    "for col in X_encoded.select_dtypes(include='object').columns:\n",
    "    X_encoded[col] = X_encoded[col].astype('category')\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b0458",
   "metadata": {},
   "source": [
    "## 🔍 Model 1: XGBoost with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5b473ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 16:58:35,439] A new study created in memory with name: no-name-79cb9b04-c5f3-46ed-b0bf-b2f9632c0ef3\n",
      "[I 2025-07-01 16:58:36,656] Trial 0 finished with value: 0.7465086483023703 and parameters: {'max_depth': 7, 'learning_rate': 0.21336808907994123, 'n_estimators': 140, 'subsample': 0.7789044907363574, 'colsample_bytree': 0.9901488965167514}. Best is trial 0 with value: 0.7465086483023703.\n",
      "[I 2025-07-01 16:58:38,198] Trial 1 finished with value: 0.7463164638052531 and parameters: {'max_depth': 3, 'learning_rate': 0.07714809170962164, 'n_estimators': 446, 'subsample': 0.685904276505674, 'colsample_bytree': 0.6579076934556752}. Best is trial 0 with value: 0.7465086483023703.\n",
      "[I 2025-07-01 16:58:44,169] Trial 2 finished with value: 0.7560538116591928 and parameters: {'max_depth': 8, 'learning_rate': 0.022197446502952942, 'n_estimators': 668, 'subsample': 0.650613659898418, 'colsample_bytree': 0.6491621496699289}. Best is trial 2 with value: 0.7560538116591928.\n",
      "[I 2025-07-01 16:58:45,709] Trial 3 finished with value: 0.7566303651505445 and parameters: {'max_depth': 4, 'learning_rate': 0.11679127800198129, 'n_estimators': 376, 'subsample': 0.9334706240065467, 'colsample_bytree': 0.6790985666149012}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:58:49,185] Trial 4 finished with value: 0.7473414477898783 and parameters: {'max_depth': 4, 'learning_rate': 0.0354177008541767, 'n_estimators': 849, 'subsample': 0.603283004778588, 'colsample_bytree': 0.789205699415612}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:58:51,596] Trial 5 finished with value: 0.7436258808456118 and parameters: {'max_depth': 10, 'learning_rate': 0.19019527278895085, 'n_estimators': 169, 'subsample': 0.6019408495172984, 'colsample_bytree': 0.7695421677467144}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:00,327] Trial 6 finished with value: 0.7458039718129404 and parameters: {'max_depth': 10, 'learning_rate': 0.2780637559697997, 'n_estimators': 794, 'subsample': 0.7052513475048544, 'colsample_bytree': 0.7282452416669184}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:06,829] Trial 7 finished with value: 0.740550928891736 and parameters: {'max_depth': 9, 'learning_rate': 0.2129184227366225, 'n_estimators': 628, 'subsample': 0.675209086732386, 'colsample_bytree': 0.5896027267654891}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:08,636] Trial 8 finished with value: 0.7411274823830878 and parameters: {'max_depth': 6, 'learning_rate': 0.29502367646060706, 'n_estimators': 302, 'subsample': 0.7297399617507185, 'colsample_bytree': 0.5213542596576325}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:09,796] Trial 9 finished with value: 0.7430493273542601 and parameters: {'max_depth': 3, 'learning_rate': 0.2905616691200377, 'n_estimators': 325, 'subsample': 0.8836719442014649, 'colsample_bytree': 0.7162081091886356}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:14,465] Trial 10 finished with value: 0.7547085201793722 and parameters: {'max_depth': 5, 'learning_rate': 0.1128147780040038, 'n_estimators': 981, 'subsample': 0.9886256368078816, 'colsample_bytree': 0.8886729381323484}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:20,121] Trial 11 finished with value: 0.7561178731582319 and parameters: {'max_depth': 8, 'learning_rate': 0.011153897779884486, 'n_estimators': 639, 'subsample': 0.5133224066106785, 'colsample_bytree': 0.6198425270773406}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:23,757] Trial 12 finished with value: 0.7492632927610506 and parameters: {'max_depth': 7, 'learning_rate': 0.11646065515390505, 'n_estimators': 509, 'subsample': 0.542247418918251, 'colsample_bytree': 0.5132716178060924}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:25,719] Trial 13 finished with value: 0.755285073670724 and parameters: {'max_depth': 5, 'learning_rate': 0.07188846420044367, 'n_estimators': 393, 'subsample': 0.8204961954885215, 'colsample_bytree': 0.6137232769616939}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:30,817] Trial 14 finished with value: 0.7557335041639974 and parameters: {'max_depth': 8, 'learning_rate': 0.15132922552758216, 'n_estimators': 598, 'subsample': 0.9938756197000523, 'colsample_bytree': 0.8368493399021024}. Best is trial 3 with value: 0.7566303651505445.\n",
      "[I 2025-07-01 16:59:35,209] Trial 15 finished with value: 0.7581678411274824 and parameters: {'max_depth': 6, 'learning_rate': 0.0606905666437634, 'n_estimators': 746, 'subsample': 0.903848790944011, 'colsample_bytree': 0.5847028163193819}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 16:59:38,790] Trial 16 finished with value: 0.7574631646380525 and parameters: {'max_depth': 5, 'learning_rate': 0.07907223055518131, 'n_estimators': 757, 'subsample': 0.909334271633695, 'colsample_bytree': 0.5652980393317031}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 16:59:43,338] Trial 17 finished with value: 0.7574631646380525 and parameters: {'max_depth': 6, 'learning_rate': 0.055639606809326655, 'n_estimators': 758, 'subsample': 0.8547232166160263, 'colsample_bytree': 0.5651591817982531}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 16:59:47,740] Trial 18 finished with value: 0.752017937219731 and parameters: {'max_depth': 5, 'learning_rate': 0.0966731081882545, 'n_estimators': 939, 'subsample': 0.9119618118404688, 'colsample_bytree': 0.554640751458216}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 16:59:51,900] Trial 19 finished with value: 0.7526585522101217 and parameters: {'max_depth': 6, 'learning_rate': 0.14909435315956263, 'n_estimators': 733, 'subsample': 0.783581381083426, 'colsample_bytree': 0.504779931471085}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 16:59:55,196] Trial 20 finished with value: 0.7575912876361307 and parameters: {'max_depth': 4, 'learning_rate': 0.04269568333906692, 'n_estimators': 877, 'subsample': 0.9340850628494317, 'colsample_bytree': 0.5637773130344808}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 16:59:58,610] Trial 21 finished with value: 0.7563741191543882 and parameters: {'max_depth': 4, 'learning_rate': 0.04857457762457085, 'n_estimators': 887, 'subsample': 0.9446205526959629, 'colsample_bytree': 0.5634766743929088}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 17:00:02,589] Trial 22 finished with value: 0.7513132607303011 and parameters: {'max_depth': 5, 'learning_rate': 0.06980319195439152, 'n_estimators': 808, 'subsample': 0.8498729646396209, 'colsample_bytree': 0.5969219114324208}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 17:00:05,651] Trial 23 finished with value: 0.7533632286995515 and parameters: {'max_depth': 4, 'learning_rate': 0.08559432862049429, 'n_estimators': 711, 'subsample': 0.9028484281364464, 'colsample_bytree': 0.694092665420427}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 17:00:08,363] Trial 24 finished with value: 0.7530429212043562 and parameters: {'max_depth': 3, 'learning_rate': 0.03703771702963804, 'n_estimators': 899, 'subsample': 0.9556142919912649, 'colsample_bytree': 0.638563762546266}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 17:00:14,703] Trial 25 finished with value: 0.7483664317745036 and parameters: {'max_depth': 6, 'learning_rate': 0.1358593714199245, 'n_estimators': 999, 'subsample': 0.8656354739710658, 'colsample_bytree': 0.5473795822745391}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 17:00:19,068] Trial 26 finished with value: 0.7556053811659192 and parameters: {'max_depth': 5, 'learning_rate': 0.056844615870724625, 'n_estimators': 836, 'subsample': 0.8162379492481298, 'colsample_bytree': 0.5919872019258716}. Best is trial 15 with value: 0.7581678411274824.\n",
      "[I 2025-07-01 17:00:22,678] Trial 27 finished with value: 0.7596412556053812 and parameters: {'max_depth': 7, 'learning_rate': 0.09846044433574874, 'n_estimators': 538, 'subsample': 0.9646402996640652, 'colsample_bytree': 0.5331864958137411}. Best is trial 27 with value: 0.7596412556053812.\n",
      "[I 2025-07-01 17:00:26,331] Trial 28 finished with value: 0.7563100576553491 and parameters: {'max_depth': 7, 'learning_rate': 0.1768692286852673, 'n_estimators': 553, 'subsample': 0.9685428512302803, 'colsample_bytree': 0.5014555762329176}. Best is trial 27 with value: 0.7596412556053812.\n",
      "[I 2025-07-01 17:00:32,115] Trial 29 finished with value: 0.7472133247918001 and parameters: {'max_depth': 9, 'learning_rate': 0.098578408281265, 'n_estimators': 500, 'subsample': 0.7693851143677968, 'colsample_bytree': 0.9503146314779102}. Best is trial 27 with value: 0.7596412556053812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[6978 1484]\n",
      " [2268 4880]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      8462\n",
      "           1       0.77      0.68      0.72      7148\n",
      "\n",
      "    accuracy                           0.76     15610\n",
      "   macro avg       0.76      0.75      0.76     15610\n",
      "weighted avg       0.76      0.76      0.76     15610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'enable_categorical': True,\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy\n",
    "\n",
    "# Run Optuna Study\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "\n",
    "# Final model with best parameters\n",
    "best_params_xgb = study_xgb.best_params\n",
    "best_params_xgb.update({\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'logloss',\n",
    "    'enable_categorical': True\n",
    "})\n",
    "\n",
    "final_xgb = xgb.XGBClassifier(**best_params_xgb)\n",
    "final_xgb.fit(X_train, y_train)\n",
    "preds_xgb = final_xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds_xgb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a8a0a",
   "metadata": {},
   "source": [
    "## 🔍 Model 2: LightGBM with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8c92ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 17:01:29,910] A new study created in memory with name: no-name-bf0730bd-622c-43f9-8b58-3201d394021d\n",
      "[I 2025-07-01 17:01:31,701] Trial 0 finished with value: 0.7483023702754644 and parameters: {'max_depth': 4, 'learning_rate': 0.23553809196119352, 'n_estimators': 471, 'num_leaves': 242, 'feature_fraction': 0.6498809518634763, 'bagging_fraction': 0.7467472269571367, 'bagging_freq': 7}. Best is trial 0 with value: 0.7483023702754644.\n",
      "[I 2025-07-01 17:01:32,133] Trial 1 finished with value: 0.7556053811659192 and parameters: {'max_depth': 3, 'learning_rate': 0.13911311615537464, 'n_estimators': 162, 'num_leaves': 100, 'feature_fraction': 0.9622771696502093, 'bagging_fraction': 0.9408174011550657, 'bagging_freq': 4}. Best is trial 1 with value: 0.7556053811659192.\n",
      "[I 2025-07-01 17:01:47,592] Trial 2 finished with value: 0.7457399103139013 and parameters: {'max_depth': 9, 'learning_rate': 0.25597204014753483, 'n_estimators': 619, 'num_leaves': 119, 'feature_fraction': 0.6313683709232726, 'bagging_fraction': 0.863701586742357, 'bagging_freq': 2}. Best is trial 1 with value: 0.7556053811659192.\n",
      "[I 2025-07-01 17:02:13,475] Trial 3 finished with value: 0.7590647021140294 and parameters: {'max_depth': 9, 'learning_rate': 0.09135138104032615, 'n_estimators': 909, 'num_leaves': 154, 'feature_fraction': 0.7099824364260391, 'bagging_fraction': 0.9452925540924016, 'bagging_freq': 1}. Best is trial 3 with value: 0.7590647021140294.\n",
      "[I 2025-07-01 17:02:26,433] Trial 4 finished with value: 0.7414477898782832 and parameters: {'max_depth': 8, 'learning_rate': 0.18864083102623988, 'n_estimators': 559, 'num_leaves': 240, 'feature_fraction': 0.6481053078118707, 'bagging_fraction': 0.6077985790905586, 'bagging_freq': 4}. Best is trial 3 with value: 0.7590647021140294.\n",
      "[I 2025-07-01 17:02:27,946] Trial 5 finished with value: 0.7443946188340808 and parameters: {'max_depth': 4, 'learning_rate': 0.25906876282499586, 'n_estimators': 364, 'num_leaves': 218, 'feature_fraction': 0.6194240176427167, 'bagging_fraction': 0.6599445498482004, 'bagging_freq': 3}. Best is trial 3 with value: 0.7590647021140294.\n",
      "[I 2025-07-01 17:02:41,843] Trial 6 finished with value: 0.7527866752081999 and parameters: {'max_depth': 9, 'learning_rate': 0.21759601777793738, 'n_estimators': 441, 'num_leaves': 182, 'feature_fraction': 0.741573344439741, 'bagging_fraction': 0.930241490911309, 'bagging_freq': 1}. Best is trial 3 with value: 0.7590647021140294.\n",
      "[I 2025-07-01 17:02:50,961] Trial 7 finished with value: 0.7671364509929532 and parameters: {'max_depth': 9, 'learning_rate': 0.024513977364043486, 'n_estimators': 284, 'num_leaves': 198, 'feature_fraction': 0.7392160042213484, 'bagging_fraction': 0.6153148684824545, 'bagging_freq': 6}. Best is trial 7 with value: 0.7671364509929532.\n",
      "[I 2025-07-01 17:02:57,742] Trial 8 finished with value: 0.7550928891736066 and parameters: {'max_depth': 8, 'learning_rate': 0.15582300918557865, 'n_estimators': 400, 'num_leaves': 86, 'feature_fraction': 0.734815592103968, 'bagging_fraction': 0.8925581242521995, 'bagging_freq': 5}. Best is trial 7 with value: 0.7671364509929532.\n",
      "[I 2025-07-01 17:03:01,847] Trial 9 finished with value: 0.7618193465727098 and parameters: {'max_depth': 6, 'learning_rate': 0.06562318271312718, 'n_estimators': 438, 'num_leaves': 84, 'feature_fraction': 0.8428182600307098, 'bagging_fraction': 0.8298992268201186, 'bagging_freq': 6}. Best is trial 7 with value: 0.7671364509929532.\n",
      "[I 2025-07-01 17:03:03,316] Trial 10 finished with value: 0.7441383728379244 and parameters: {'max_depth': 6, 'learning_rate': 0.012607711968419628, 'n_estimators': 129, 'num_leaves': 188, 'feature_fraction': 0.8549311706329827, 'bagging_fraction': 0.7252351036296663, 'bagging_freq': 7}. Best is trial 7 with value: 0.7671364509929532.\n",
      "[I 2025-07-01 17:03:05,488] Trial 11 finished with value: 0.7602178090967329 and parameters: {'max_depth': 6, 'learning_rate': 0.014731760458622623, 'n_estimators': 265, 'num_leaves': 38, 'feature_fraction': 0.8483754364922522, 'bagging_fraction': 0.8154855015191339, 'bagging_freq': 6}. Best is trial 7 with value: 0.7671364509929532.\n",
      "[I 2025-07-01 17:03:14,408] Trial 12 finished with value: 0.7568866111467009 and parameters: {'max_depth': 7, 'learning_rate': 0.07057140845273209, 'n_estimators': 716, 'num_leaves': 66, 'feature_fraction': 0.8227769875384674, 'bagging_fraction': 0.7865513988033032, 'bagging_freq': 6}. Best is trial 7 with value: 0.7671364509929532.\n",
      "[I 2025-07-01 17:03:23,067] Trial 13 finished with value: 0.7704676489429853 and parameters: {'max_depth': 10, 'learning_rate': 0.06916948692019219, 'n_estimators': 278, 'num_leaves': 159, 'feature_fraction': 0.9434742655313, 'bagging_fraction': 0.9974241874274633, 'bagging_freq': 5}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:03:31,600] Trial 14 finished with value: 0.7666239590006406 and parameters: {'max_depth': 10, 'learning_rate': 0.11108333714914036, 'n_estimators': 263, 'num_leaves': 166, 'feature_fraction': 0.998134419159506, 'bagging_fraction': 0.994758581731013, 'bagging_freq': 5}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:03:42,645] Trial 15 finished with value: 0.766111467008328 and parameters: {'max_depth': 10, 'learning_rate': 0.04754482684770315, 'n_estimators': 293, 'num_leaves': 207, 'feature_fraction': 0.9159885830849027, 'bagging_fraction': 0.697589237394949, 'bagging_freq': 5}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:03:45,475] Trial 16 finished with value: 0.7392056374119155 and parameters: {'max_depth': 10, 'learning_rate': 0.29832740982454387, 'n_estimators': 107, 'num_leaves': 127, 'feature_fraction': 0.7806939423700293, 'bagging_fraction': 0.6131770047483373, 'bagging_freq': 3}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:04:00,525] Trial 17 finished with value: 0.7588084561178732 and parameters: {'max_depth': 8, 'learning_rate': 0.048032860872744595, 'n_estimators': 707, 'num_leaves': 146, 'feature_fraction': 0.908533634989876, 'bagging_fraction': 0.6650076364648786, 'bagging_freq': 6}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:04:03,983] Trial 18 finished with value: 0.7637411915438821 and parameters: {'max_depth': 7, 'learning_rate': 0.11820565832815323, 'n_estimators': 220, 'num_leaves': 206, 'feature_fraction': 0.7812256792818812, 'bagging_fraction': 0.9950099525237837, 'bagging_freq': 5}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:04:34,392] Trial 19 finished with value: 0.7641255605381166 and parameters: {'max_depth': 9, 'learning_rate': 0.03574961921413577, 'n_estimators': 994, 'num_leaves': 175, 'feature_fraction': 0.6865012572463193, 'bagging_fraction': 0.8620391922879713, 'bagging_freq': 7}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:04:47,987] Trial 20 finished with value: 0.7565663036515055 and parameters: {'max_depth': 10, 'learning_rate': 0.08560810107725857, 'n_estimators': 521, 'num_leaves': 129, 'feature_fraction': 0.8851398206441214, 'bagging_fraction': 0.7654894827790197, 'bagging_freq': 3}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:04:57,896] Trial 21 finished with value: 0.7645099295323511 and parameters: {'max_depth': 10, 'learning_rate': 0.11357002440652092, 'n_estimators': 304, 'num_leaves': 167, 'feature_fraction': 0.9957769425531076, 'bagging_fraction': 0.9875760985797756, 'bagging_freq': 5}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:05:04,366] Trial 22 finished with value: 0.7645739910313901 and parameters: {'max_depth': 10, 'learning_rate': 0.11409818924018221, 'n_estimators': 208, 'num_leaves': 155, 'feature_fraction': 0.9637531846795679, 'bagging_fraction': 0.9147498651449176, 'bagging_freq': 4}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:05:15,267] Trial 23 finished with value: 0.7590006406149904 and parameters: {'max_depth': 9, 'learning_rate': 0.16143845243573357, 'n_estimators': 329, 'num_leaves': 198, 'feature_fraction': 0.9969678170783811, 'bagging_fraction': 0.9693775314589289, 'bagging_freq': 5}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:05:20,636] Trial 24 finished with value: 0.7630365150544522 and parameters: {'max_depth': 8, 'learning_rate': 0.08732211219646573, 'n_estimators': 216, 'num_leaves': 230, 'feature_fraction': 0.9502836873873369, 'bagging_fraction': 0.8914469953600717, 'bagging_freq': 6}. Best is trial 13 with value: 0.7704676489429853.\n",
      "[I 2025-07-01 17:05:33,239] Trial 25 finished with value: 0.7706598334401025 and parameters: {'max_depth': 10, 'learning_rate': 0.0330233031920151, 'n_estimators': 370, 'num_leaves': 175, 'feature_fraction': 0.9268252303501577, 'bagging_fraction': 0.9610706119206426, 'bagging_freq': 5}. Best is trial 25 with value: 0.7706598334401025.\n",
      "[I 2025-07-01 17:05:44,476] Trial 26 finished with value: 0.7704035874439462 and parameters: {'max_depth': 9, 'learning_rate': 0.033405736984603446, 'n_estimators': 342, 'num_leaves': 190, 'feature_fraction': 0.8928820895149444, 'bagging_fraction': 0.9579299255605566, 'bagging_freq': 4}. Best is trial 25 with value: 0.7706598334401025.\n",
      "[I 2025-07-01 17:05:50,181] Trial 27 finished with value: 0.7686739269698911 and parameters: {'max_depth': 7, 'learning_rate': 0.06788237885414464, 'n_estimators': 373, 'num_leaves': 140, 'feature_fraction': 0.8923074737918395, 'bagging_fraction': 0.961826261579477, 'bagging_freq': 4}. Best is trial 25 with value: 0.7706598334401025.\n",
      "[I 2025-07-01 17:06:13,229] Trial 28 finished with value: 0.7681614349775785 and parameters: {'max_depth': 10, 'learning_rate': 0.045043041621242605, 'n_estimators': 535, 'num_leaves': 252, 'feature_fraction': 0.9335520318373031, 'bagging_fraction': 0.9006024820915527, 'bagging_freq': 3}. Best is trial 25 with value: 0.7706598334401025.\n",
      "[I 2025-07-01 17:06:16,076] Trial 29 finished with value: 0.766175528507367 and parameters: {'max_depth': 5, 'learning_rate': 0.03196860120764468, 'n_estimators': 481, 'num_leaves': 223, 'feature_fraction': 0.8787257365727186, 'bagging_fraction': 0.9613702740120595, 'bagging_freq': 4}. Best is trial 25 with value: 0.7706598334401025.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "FrozenTrial(number=25, state=TrialState.COMPLETE, values=[0.7706598334401025], datetime_start=datetime.datetime(2025, 7, 1, 17, 5, 20, 636672), datetime_complete=datetime.datetime(2025, 7, 1, 17, 5, 33, 239316), params={'max_depth': 10, 'learning_rate': 0.0330233031920151, 'n_estimators': 370, 'num_leaves': 175, 'feature_fraction': 0.9268252303501577, 'bagging_fraction': 0.9610706119206426, 'bagging_freq': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'n_estimators': IntDistribution(high=1000, log=False, low=100, step=1), 'num_leaves': IntDistribution(high=256, log=False, low=31, step=1), 'feature_fraction': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'bagging_fraction': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'bagging_freq': IntDistribution(high=7, log=False, low=1, step=1)}, trial_id=25, value=None)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7108 1354]\n",
      " [2226 4922]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80      8462\n",
      "           1       0.78      0.69      0.73      7148\n",
      "\n",
      "    accuracy                           0.77     15610\n",
      "   macro avg       0.77      0.76      0.77     15610\n",
      "weighted avg       0.77      0.77      0.77     15610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code for Optuna tuning of LightGBM goes here\n",
    "import lightgbm as lgb\n",
    "# Objective function for Optuna\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 256),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7)\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "# Run the Optuna study\n",
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=30)\n",
    "\n",
    "# Train final model using best parameters\n",
    "print(\"Best Trial:\")\n",
    "print(study_lgb.best_trial)\n",
    "\n",
    "best_params_lgb = study_lgb.best_params\n",
    "final_lgb = lgb.LGBMClassifier(**best_params_lgb)\n",
    "final_lgb.fit(X_train, y_train)\n",
    "preds_lgb = final_lgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds_lgb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds_lgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050cfa8",
   "metadata": {},
   "source": [
    "## 🔍 Model 3: CatBoost with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4faa6e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 17:14:23,310] A new study created in memory with name: no-name-14804748-d3f5-4daf-b02b-6fb983a55980\n",
      "[I 2025-07-01 17:14:30,069] Trial 0 finished with value: 0.7762972453555413 and parameters: {'depth': 7, 'learning_rate': 0.27942876055489146, 'iterations': 385, 'l2_leaf_reg': 3.7666709530600704, 'random_strength': 2.869201368913176, 'bagging_temperature': 0.7133209374572772, 'border_count': 160}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:14:33,212] Trial 1 finished with value: 0.7744394618834081 and parameters: {'depth': 6, 'learning_rate': 0.16248946100352665, 'iterations': 216, 'l2_leaf_reg': 6.4093189446122425, 'random_strength': 4.159365909459203, 'bagging_temperature': 0.8789546266081864, 'border_count': 101}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:14:39,105] Trial 2 finished with value: 0.7750800768737989 and parameters: {'depth': 8, 'learning_rate': 0.20498379926146884, 'iterations': 287, 'l2_leaf_reg': 4.038818635618964, 'random_strength': 1.727964036631263, 'bagging_temperature': 0.5129841118717183, 'border_count': 227}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:14:44,389] Trial 3 finished with value: 0.7718129404228059 and parameters: {'depth': 4, 'learning_rate': 0.2843396061984538, 'iterations': 518, 'l2_leaf_reg': 2.468088099982753, 'random_strength': 1.1016073292155997, 'bagging_temperature': 0.8540135997168264, 'border_count': 62}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:14:56,323] Trial 4 finished with value: 0.7741191543882127 and parameters: {'depth': 7, 'learning_rate': 0.2646210495665372, 'iterations': 700, 'l2_leaf_reg': 6.67683915693209, 'random_strength': 7.442164792316067, 'bagging_temperature': 0.48202099433925916, 'border_count': 122}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:15:16,672] Trial 5 finished with value: 0.7719410634208841 and parameters: {'depth': 8, 'learning_rate': 0.1932788685907023, 'iterations': 994, 'l2_leaf_reg': 5.834212076158291, 'random_strength': 5.754279449316383, 'bagging_temperature': 0.7331218126279845, 'border_count': 164}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:15:28,776] Trial 6 finished with value: 0.7622037155669442 and parameters: {'depth': 7, 'learning_rate': 0.014504234001207322, 'iterations': 731, 'l2_leaf_reg': 1.2991357421419651, 'random_strength': 1.5963833187196013, 'bagging_temperature': 0.3768610662025864, 'border_count': 42}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:15:54,617] Trial 7 finished with value: 0.7716207559256887 and parameters: {'depth': 10, 'learning_rate': 0.20098275200792268, 'iterations': 718, 'l2_leaf_reg': 7.986239408541342, 'random_strength': 7.373646744875089, 'bagging_temperature': 0.6877041658015782, 'border_count': 40}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:15:58,874] Trial 8 finished with value: 0.7449711723254324 and parameters: {'depth': 7, 'learning_rate': 0.04439242288537776, 'iterations': 273, 'l2_leaf_reg': 2.442447433278543, 'random_strength': 7.683899748817093, 'bagging_temperature': 0.31572537067200135, 'border_count': 74}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:05,771] Trial 9 finished with value: 0.7733504163997438 and parameters: {'depth': 9, 'learning_rate': 0.20808609310790754, 'iterations': 269, 'l2_leaf_reg': 4.218776972809513, 'random_strength': 4.567757017880113, 'bagging_temperature': 0.7409877608851368, 'border_count': 78}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:11,858] Trial 10 finished with value: 0.7723894939141576 and parameters: {'depth': 5, 'learning_rate': 0.07931112330606009, 'iterations': 497, 'l2_leaf_reg': 9.879924111984266, 'random_strength': 3.2257583634932487, 'bagging_temperature': 0.07192188650753772, 'border_count': 176}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:22,202] Trial 11 finished with value: 0.7723254324151185 and parameters: {'depth': 9, 'learning_rate': 0.24831624290709986, 'iterations': 384, 'l2_leaf_reg': 4.313249561127116, 'random_strength': 2.5796357792608937, 'bagging_temperature': 0.6148072797827987, 'border_count': 237}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:23,907] Trial 12 finished with value: 0.7705317104420244 and parameters: {'depth': 8, 'learning_rate': 0.11799939319212781, 'iterations': 128, 'l2_leaf_reg': 4.075178373445059, 'random_strength': 2.4631630466408336, 'bagging_temperature': 0.5522172447916713, 'border_count': 230}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:30,122] Trial 13 finished with value: 0.7758488148622678 and parameters: {'depth': 6, 'learning_rate': 0.2388034905628017, 'iterations': 426, 'l2_leaf_reg': 3.1394410520935963, 'random_strength': 9.32345021653286, 'bagging_temperature': 0.1890790934628679, 'border_count': 195}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:35,424] Trial 14 finished with value: 0.7740550928891736 and parameters: {'depth': 5, 'learning_rate': 0.2928716001059681, 'iterations': 428, 'l2_leaf_reg': 2.398505177272196, 'random_strength': 9.479024663437324, 'bagging_temperature': 0.025921039200450524, 'border_count': 195}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:44,248] Trial 15 finished with value: 0.7748878923766817 and parameters: {'depth': 6, 'learning_rate': 0.24503168437482922, 'iterations': 595, 'l2_leaf_reg': 1.1241925838078726, 'random_strength': 9.550256819820842, 'bagging_temperature': 0.17563954550662242, 'border_count': 139}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:50,163] Trial 16 finished with value: 0.7755925688661115 and parameters: {'depth': 6, 'learning_rate': 0.23456058473955677, 'iterations': 405, 'l2_leaf_reg': 3.078161841516712, 'random_strength': 5.924252852674238, 'bagging_temperature': 0.9858448992384626, 'border_count': 200}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:56,372] Trial 17 finished with value: 0.7705957719410634 and parameters: {'depth': 4, 'learning_rate': 0.13685105107802442, 'iterations': 604, 'l2_leaf_reg': 5.118678747669717, 'random_strength': 4.428154836684261, 'bagging_temperature': 0.23687740427580237, 'border_count': 154}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:16:57,362] Trial 18 finished with value: 0.766944266495836 and parameters: {'depth': 5, 'learning_rate': 0.2939278608591042, 'iterations': 112, 'l2_leaf_reg': 3.2435975723388824, 'random_strength': 8.451394707326974, 'bagging_temperature': 0.39214689270187925, 'border_count': 189}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:17:10,252] Trial 19 finished with value: 0.7704035874439462 and parameters: {'depth': 6, 'learning_rate': 0.17136970508296545, 'iterations': 877, 'l2_leaf_reg': 7.711670294622766, 'random_strength': 6.708626854316132, 'bagging_temperature': 0.1771396646455733, 'border_count': 131}. Best is trial 0 with value: 0.7762972453555413.\n",
      "[I 2025-07-01 17:17:18,825] Trial 20 finished with value: 0.7764253683536195 and parameters: {'depth': 9, 'learning_rate': 0.23369341715704162, 'iterations': 328, 'l2_leaf_reg': 5.557767576085904, 'random_strength': 3.676883873061694, 'bagging_temperature': 0.8291315217645151, 'border_count': 110}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:17:28,317] Trial 21 finished with value: 0.7714926329276105 and parameters: {'depth': 9, 'learning_rate': 0.2630832290786482, 'iterations': 366, 'l2_leaf_reg': 5.433743597206888, 'random_strength': 3.484642527939566, 'bagging_temperature': 0.8604809608362695, 'border_count': 108}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:17:45,162] Trial 22 finished with value: 0.7672005124919923 and parameters: {'depth': 10, 'learning_rate': 0.22978164527452843, 'iterations': 472, 'l2_leaf_reg': 4.921251377649085, 'random_strength': 5.187716611648667, 'bagging_temperature': 0.9945699634531315, 'border_count': 217}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:17:51,845] Trial 23 finished with value: 0.7747597693786035 and parameters: {'depth': 8, 'learning_rate': 0.22448071381127266, 'iterations': 332, 'l2_leaf_reg': 3.287565258880983, 'random_strength': 3.2871078479076306, 'bagging_temperature': 0.6490500253581766, 'border_count': 167}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:17:55,579] Trial 24 finished with value: 0.7729660474055093 and parameters: {'depth': 7, 'learning_rate': 0.2619028311890902, 'iterations': 222, 'l2_leaf_reg': 1.8361106540628673, 'random_strength': 2.702084886945097, 'bagging_temperature': 0.7815093660872703, 'border_count': 103}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:18:05,042] Trial 25 finished with value: 0.7713004484304933 and parameters: {'depth': 7, 'learning_rate': 0.27575908078798006, 'iterations': 574, 'l2_leaf_reg': 7.099916610658988, 'random_strength': 3.95034912748228, 'bagging_temperature': 0.8090344426821672, 'border_count': 149}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:18:16,959] Trial 26 finished with value: 0.7731582319026266 and parameters: {'depth': 9, 'learning_rate': 0.1843788227370135, 'iterations': 465, 'l2_leaf_reg': 5.848644239325399, 'random_strength': 8.630711620673482, 'bagging_temperature': 0.5731208089465778, 'border_count': 253}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:18:18,667] Trial 27 finished with value: 0.7736066623959 and parameters: {'depth': 6, 'learning_rate': 0.2198684708795801, 'iterations': 184, 'l2_leaf_reg': 4.788051962478196, 'random_strength': 5.257152167387164, 'bagging_temperature': 0.938653370320212, 'border_count': 181}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:18:31,406] Trial 28 finished with value: 0.7755285073670724 and parameters: {'depth': 8, 'learning_rate': 0.1255039083353082, 'iterations': 649, 'l2_leaf_reg': 3.5529055903544338, 'random_strength': 6.654061140709886, 'bagging_temperature': 0.6927408783765802, 'border_count': 123}. Best is trial 20 with value: 0.7764253683536195.\n",
      "[I 2025-07-01 17:18:35,309] Trial 29 finished with value: 0.7733504163997438 and parameters: {'depth': 5, 'learning_rate': 0.1680122462207657, 'iterations': 322, 'l2_leaf_reg': 8.927560722296842, 'random_strength': 4.815943596552875, 'bagging_temperature': 0.45711614458560257, 'border_count': 207}. Best is trial 20 with value: 0.7764253683536195.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "FrozenTrial(number=20, state=TrialState.COMPLETE, values=[0.7764253683536195], datetime_start=datetime.datetime(2025, 7, 1, 17, 17, 10, 253043), datetime_complete=datetime.datetime(2025, 7, 1, 17, 17, 18, 825554), params={'depth': 9, 'learning_rate': 0.23369341715704162, 'iterations': 328, 'l2_leaf_reg': 5.557767576085904, 'random_strength': 3.676883873061694, 'bagging_temperature': 0.8291315217645151, 'border_count': 110}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'depth': IntDistribution(high=10, log=False, low=4, step=1), 'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'iterations': IntDistribution(high=1000, log=False, low=100, step=1), 'l2_leaf_reg': FloatDistribution(high=10.0, log=False, low=1.0, step=None), 'random_strength': FloatDistribution(high=10.0, log=False, low=1.0, step=None), 'bagging_temperature': FloatDistribution(high=1.0, log=False, low=0.0, step=None), 'border_count': IntDistribution(high=255, log=False, low=32, step=1)}, trial_id=20, value=None)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7163 1299]\n",
      " [2191 4957]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.80      8462\n",
      "           1       0.79      0.69      0.74      7148\n",
      "\n",
      "    accuracy                           0.78     15610\n",
      "   macro avg       0.78      0.77      0.77     15610\n",
      "weighted avg       0.78      0.78      0.77     15610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Clean up categories — convert to string and fill NaN\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "for col in X_train.select_dtypes(include='category').columns:\n",
    "    X_train[col] = X_train[col].astype(str).fillna(\"missing\")\n",
    "    X_test[col] = X_test[col].astype(str).fillna(\"missing\")\n",
    "\n",
    "# Define categorical feature names (not indices)\n",
    "cat_features = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Define Optuna objective for CatBoost\n",
    "def objective_cat(trial):\n",
    "    params = {\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'Accuracy',\n",
    "        'verbose': 0,\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1.0, 10.0),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255)\n",
    "    }\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    test_pool = Pool(X_test, y_test, cat_features=cat_features)\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(train_pool)\n",
    "    preds = model.predict(test_pool)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "# Run Optuna\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_cat, n_trials=30)\n",
    "\n",
    "# Final model training\n",
    "print(\"Best Trial:\")\n",
    "print(study_cat.best_trial)\n",
    "\n",
    "best_params_cat = study_cat.best_params\n",
    "final_cat = CatBoostClassifier(**best_params_cat, verbose=0)\n",
    "final_cat.fit(Pool(X_train, y_train, cat_features=cat_features))\n",
    "preds_cat = final_cat.predict(Pool(X_test, cat_features=cat_features))\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds_cat))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds_cat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fcfa44",
   "metadata": {},
   "source": [
    "## Model 4: GradientBoostingClassifier with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "497b426b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 17:37:08,881] A new study created in memory with name: no-name-64606dd3-e0b7-4bfc-b311-fc595bc391e8\n",
      "[I 2025-07-01 17:37:11,611] Trial 0 finished with value: 0.7518898142216528 and parameters: {'n_estimators': 146, 'learning_rate': 0.15723376816196039, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9076467585015491, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7518898142216528.\n",
      "[I 2025-07-01 17:37:15,523] Trial 1 finished with value: 0.7441383728379244 and parameters: {'n_estimators': 289, 'learning_rate': 0.09910592352981151, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.8128949041834826, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7518898142216528.\n",
      "[I 2025-07-01 17:37:20,057] Trial 2 finished with value: 0.7574631646380525 and parameters: {'n_estimators': 273, 'learning_rate': 0.1804533457435601, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9003843757273213, 'max_features': 'log2'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:23,300] Trial 3 finished with value: 0.7449711723254324 and parameters: {'n_estimators': 188, 'learning_rate': 0.0918074279038431, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.8922723895230165, 'max_features': 'log2'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:26,365] Trial 4 finished with value: 0.7465086483023703 and parameters: {'n_estimators': 276, 'learning_rate': 0.14126259490808313, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'subsample': 0.7192120235567816, 'max_features': 'log2'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:29,737] Trial 5 finished with value: 0.7519538757206918 and parameters: {'n_estimators': 252, 'learning_rate': 0.17646587985424542, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.7636749904000515, 'max_features': 'log2'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:31,442] Trial 6 finished with value: 0.7273542600896861 and parameters: {'n_estimators': 108, 'learning_rate': 0.05310870746343357, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.7481788707636058, 'max_features': 'log2'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:33,508] Trial 7 finished with value: 0.7368353619474696 and parameters: {'n_estimators': 214, 'learning_rate': 0.15177414441190093, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9502141356928513, 'max_features': 'log2'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:36,377] Trial 8 finished with value: 0.737219730941704 and parameters: {'n_estimators': 155, 'learning_rate': 0.0693483479064873, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9016090876404831, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:40,238] Trial 9 finished with value: 0.7552210121716848 and parameters: {'n_estimators': 250, 'learning_rate': 0.14284007458738943, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7383713069039134, 'max_features': 'log2'}. Best is trial 2 with value: 0.7574631646380525.\n",
      "[I 2025-07-01 17:37:45,366] Trial 10 finished with value: 0.7598334401024984 and parameters: {'n_estimators': 231, 'learning_rate': 0.1998492326863883, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.9663827366554456, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.7598334401024984.\n",
      "[I 2025-07-01 17:37:50,491] Trial 11 finished with value: 0.760345932094811 and parameters: {'n_estimators': 221, 'learning_rate': 0.19344239081761874, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.9996971552561811, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.760345932094811.\n",
      "[I 2025-07-01 17:37:55,561] Trial 12 finished with value: 0.7612427930813581 and parameters: {'n_estimators': 223, 'learning_rate': 0.1877141463372685, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.988551790320046, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:37:59,946] Trial 13 finished with value: 0.7597053171044202 and parameters: {'n_estimators': 190, 'learning_rate': 0.19907143357069573, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.9909585422032782, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:38:04,962] Trial 14 finished with value: 0.7601537475976938 and parameters: {'n_estimators': 215, 'learning_rate': 0.17381138274887156, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.9948020281406214, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:38:08,565] Trial 15 finished with value: 0.7550928891736066 and parameters: {'n_estimators': 168, 'learning_rate': 0.11957494284663706, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.8459203392272208, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:38:12,893] Trial 16 finished with value: 0.7546444586803331 and parameters: {'n_estimators': 241, 'learning_rate': 0.12058685807741744, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.9374174496494876, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:38:17,159] Trial 17 finished with value: 0.7598334401024984 and parameters: {'n_estimators': 207, 'learning_rate': 0.1847092841932154, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.8497527220289921, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:38:20,372] Trial 18 finished with value: 0.7538116591928251 and parameters: {'n_estimators': 174, 'learning_rate': 0.16463077358178585, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.9668863364994692, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:38:24,006] Trial 19 finished with value: 0.7571428571428571 and parameters: {'n_estimators': 131, 'learning_rate': 0.18962320221617193, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9993646875052209, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.7612427930813581.\n",
      "[I 2025-07-01 17:38:28,983] Trial 20 finished with value: 0.7613068545803972 and parameters: {'n_estimators': 230, 'learning_rate': 0.16586467547237793, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9296578548201411, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7613068545803972.\n",
      "[I 2025-07-01 17:38:34,145] Trial 21 finished with value: 0.7584881486226778 and parameters: {'n_estimators': 230, 'learning_rate': 0.16490153398108426, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9333722905187141, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7613068545803972.\n",
      "[I 2025-07-01 17:38:40,054] Trial 22 finished with value: 0.7631005765534914 and parameters: {'n_estimators': 259, 'learning_rate': 0.18853248884417098, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9676093763881931, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.7631005765534914.\n",
      "[I 2025-07-01 17:38:46,047] Trial 23 finished with value: 0.7621396540679052 and parameters: {'n_estimators': 264, 'learning_rate': 0.17067292190134215, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9644309748649835, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.7631005765534914.\n",
      "[I 2025-07-01 17:38:51,458] Trial 24 finished with value: 0.7549647661755285 and parameters: {'n_estimators': 299, 'learning_rate': 0.13577484613217775, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8772497491720097, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.7631005765534914.\n",
      "[I 2025-07-01 17:38:57,288] Trial 25 finished with value: 0.762011531069827 and parameters: {'n_estimators': 267, 'learning_rate': 0.16763279510129303, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9286966957153505, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.7631005765534914.\n",
      "[I 2025-07-01 17:39:04,179] Trial 26 finished with value: 0.7629724535554132 and parameters: {'n_estimators': 260, 'learning_rate': 0.15316900102373343, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9634318162960597, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.7631005765534914.\n",
      "[I 2025-07-01 17:39:11,055] Trial 27 finished with value: 0.7627162075592568 and parameters: {'n_estimators': 260, 'learning_rate': 0.13393012061827023, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9605524514917921, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.7631005765534914.\n",
      "[I 2025-07-01 17:39:17,839] Trial 28 finished with value: 0.7634208840486867 and parameters: {'n_estimators': 284, 'learning_rate': 0.12939707142464893, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.8090178603431958, 'max_features': 'sqrt'}. Best is trial 28 with value: 0.7634208840486867.\n",
      "[I 2025-07-01 17:39:24,469] Trial 29 finished with value: 0.7645739910313901 and parameters: {'n_estimators': 286, 'learning_rate': 0.10561143960860893, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7863867061472648, 'max_features': 'sqrt'}. Best is trial 29 with value: 0.7645739910313901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "FrozenTrial(number=29, state=TrialState.COMPLETE, values=[0.7645739910313901], datetime_start=datetime.datetime(2025, 7, 1, 17, 39, 17, 839996), datetime_complete=datetime.datetime(2025, 7, 1, 17, 39, 24, 469548), params={'n_estimators': 286, 'learning_rate': 0.10561143960860893, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7863867061472648, 'max_features': 'sqrt'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=300, log=False, low=100, step=1), 'learning_rate': FloatDistribution(high=0.2, log=False, low=0.05, step=None), 'max_depth': IntDistribution(high=6, log=False, low=3, step=1), 'min_samples_split': IntDistribution(high=5, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=3, log=False, low=1, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.7, step=None), 'max_features': CategoricalDistribution(choices=('sqrt', 'log2'))}, trial_id=29, value=None)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7124 1338]\n",
      " [2337 4811]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79      8462\n",
      "           1       0.78      0.67      0.72      7148\n",
      "\n",
      "    accuracy                           0.76     15610\n",
      "   macro avg       0.77      0.76      0.76     15610\n",
      "weighted avg       0.77      0.76      0.76     15610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "X = X.copy()  # Just to be safe\n",
    "\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))  # Convert NaN and objects to string first\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Optuna objective function\n",
    "def objective_gb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),  # Lower\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.2),  # Focused range\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),  # Shallower trees\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 5),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2'])  # No None\n",
    "    }\n",
    "\n",
    "    model = GradientBoostingClassifier(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "\n",
    "# Run Optuna\n",
    "study_gb = optuna.create_study(direction='maximize')\n",
    "study_gb.optimize(objective_gb, n_trials=30)\n",
    "\n",
    "# Final model\n",
    "print(\"Best Trial:\")\n",
    "print(study_gb.best_trial)\n",
    "\n",
    "best_params_gb = study_gb.best_params\n",
    "final_gb = GradientBoostingClassifier(**best_params_gb, random_state=42)\n",
    "final_gb.fit(X_train, y_train)\n",
    "preds_gb = final_gb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds_gb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b6709",
   "metadata": {},
   "source": [
    "### Model Leaderboard (Based on Classification Reports)\n",
    "\n",
    "| Model                | Accuracy | Precision | Recall | F1 Score |\n",
    "|----------------------|----------|-----------|--------|----------|\n",
    "| **CatBoost**         | 0.78     | 0.79      | 0.69   | 0.74     |\n",
    "| **LightGBM**         | 0.77     | 0.78      | 0.69   | 0.73     |\n",
    "| **XGBoost**          | 0.76     | 0.77      | 0.68   | 0.72     |\n",
    "| **GradientBoosting** | 0.76     | 0.78      | 0.67   | 0.72     |\n",
    "\n",
    "**Notes:**\n",
    "- All models were tuned using Optuna.\n",
    "- Input data and evaluation method were consistent across models.\n",
    "- CatBoost achieved the highest F1-score and accuracy overall.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
