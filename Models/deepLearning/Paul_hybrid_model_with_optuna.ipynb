{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbb1529",
   "metadata": {},
   "source": [
    "# Predicting Patient Readmission with a Hybrid Deep Learning Model\n",
    "\n",
    "### Project Objective\n",
    "This notebook develops and optimizes a deep learning model to predict the likelihood of a patient being readmitted to a hospital. The goal is to create a robust, high-performing model by leveraging a hybrid architecture and systematic hyperparameter tuning.\n",
    "\n",
    "### Methodology\n",
    "The core of this solution is a hybrid neural network that processes different types of features using specialized layers:\n",
    "*   **1D Convolutional Neural Network (CNN):** Used to extract spatial patterns from the numerical and one-hot encoded categorical features.\n",
    "*   **Entity Embeddings:** Used to create dense, meaningful vector representations of high-cardinality categorical features, capturing complex relationships between their categories.\n",
    "*   **Optuna Hyperparameter Tuning:** We employ the Optuna framework to systematically search for the optimal model configuration, including learning rate, layer sizes, and dropout rates, ensuring a data-driven approach to model design.\n",
    "*   **Robust Evaluation:** The model is trained using a rigorous process that prevents overfitting by identifying the optimal training duration and is evaluated on a completely unseen test set to provide a reliable measure of its real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb5ed437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Embedding, concatenate, Reshape, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f5e5f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ GPU(s) detected!\n",
      " - PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "TensorFlow will use the GPU by default when available.\n"
     ]
    }
   ],
   "source": [
    "# List physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"üöÄ GPU(s) detected!\")\n",
    "    for gpu in gpus:\n",
    "        print(f\" - {gpu}\")\n",
    "    print(\"TensorFlow will use the GPU by default when available.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Using CPU only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02cd8353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_726/1422035621.py:4: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../../dataPreprocessing/medical_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (78049, 202)\n",
      "Data head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>gender</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>discharge_disposition</th>\n",
       "      <th>admission_source</th>\n",
       "      <th>mb_admission_grp_1_ct</th>\n",
       "      <th>mb_admission_grp_2_ct</th>\n",
       "      <th>mb_discharge_grp_1_ct</th>\n",
       "      <th>mb_discharge_grp_2_ct</th>\n",
       "      <th>mb_admission_type_ct</th>\n",
       "      <th>distinct_diag_count</th>\n",
       "      <th>diagnosis_1</th>\n",
       "      <th>diagnosis_2</th>\n",
       "      <th>diagnosis_3</th>\n",
       "      <th>diag_1_freq</th>\n",
       "      <th>diag_2_freq</th>\n",
       "      <th>diag_3_freq</th>\n",
       "      <th>LTIS_38_ind</th>\n",
       "      <th>LTIS_40_ind</th>\n",
       "      <th>LTIS_36_ind</th>\n",
       "      <th>LTIS_320_ind</th>\n",
       "      <th>LTIS_324_ind</th>\n",
       "      <th>CE_410_ind</th>\n",
       "      <th>CE_430_ind</th>\n",
       "      <th>CE_431_ind</th>\n",
       "      <th>CE_415_ind</th>\n",
       "      <th>CE_428_ind</th>\n",
       "      <th>CMN_155_ind</th>\n",
       "      <th>CMN_162_ind</th>\n",
       "      <th>CMN_191_ind</th>\n",
       "      <th>CMN_197_ind</th>\n",
       "      <th>CMN_199_ind</th>\n",
       "      <th>OF_570_ind</th>\n",
       "      <th>OF_584_ind</th>\n",
       "      <th>OF_585_ind</th>\n",
       "      <th>OF_277_ind</th>\n",
       "      <th>NBD_331_ind</th>\n",
       "      <th>NBD_340_ind</th>\n",
       "      <th>NBD_780_ind</th>\n",
       "      <th>NBD_852_ind</th>\n",
       "      <th>STI_806_ind</th>\n",
       "      <th>STI_861_ind</th>\n",
       "      <th>STI_864_ind</th>\n",
       "      <th>STI_958_ind</th>\n",
       "      <th>OCC_250_ind</th>\n",
       "      <th>OCC_995_ind</th>\n",
       "      <th>OCC_986_ind</th>\n",
       "      <th>OCC_989_ind</th>\n",
       "      <th>diagnosis_combo_frequency</th>\n",
       "      <th>sorted_diag_1</th>\n",
       "      <th>sorted_diag_2</th>\n",
       "      <th>sorted_diag_3</th>\n",
       "      <th>sorted_diag_1_frequency</th>\n",
       "      <th>sorted_diag_2_frequency</th>\n",
       "      <th>sorted_diag_3_frequency</th>\n",
       "      <th>diagnosis_combo_string</th>\n",
       "      <th>is_high_risk_combo</th>\n",
       "      <th>dx_428_ind_max</th>\n",
       "      <th>dx_428_ind_sum</th>\n",
       "      <th>dx_403_ind_max</th>\n",
       "      <th>dx_403_ind_sum</th>\n",
       "      <th>dx_707_ind_max</th>\n",
       "      <th>dx_707_ind_sum</th>\n",
       "      <th>dx_585_ind_max</th>\n",
       "      <th>dx_585_ind_sum</th>\n",
       "      <th>dx_491_ind_max</th>\n",
       "      <th>dx_491_ind_sum</th>\n",
       "      <th>dx_396_ind_max</th>\n",
       "      <th>dx_396_ind_sum</th>\n",
       "      <th>dx_440_ind_max</th>\n",
       "      <th>dx_440_ind_sum</th>\n",
       "      <th>dx_453_ind_max</th>\n",
       "      <th>dx_453_ind_sum</th>\n",
       "      <th>dx_571_ind_max</th>\n",
       "      <th>dx_571_ind_sum</th>\n",
       "      <th>dx_284_ind_max</th>\n",
       "      <th>dx_284_ind_sum</th>\n",
       "      <th>dx_304_ind_max</th>\n",
       "      <th>dx_304_ind_sum</th>\n",
       "      <th>dx_482_ind_max</th>\n",
       "      <th>dx_482_ind_sum</th>\n",
       "      <th>dx_150_ind_max</th>\n",
       "      <th>dx_150_ind_sum</th>\n",
       "      <th>dx_282_ind_max</th>\n",
       "      <th>dx_282_ind_sum</th>\n",
       "      <th>dx_332_ind_max</th>\n",
       "      <th>dx_332_ind_sum</th>\n",
       "      <th>dx_443_ind_max</th>\n",
       "      <th>dx_443_ind_sum</th>\n",
       "      <th>dx_719_ind_max</th>\n",
       "      <th>dx_719_ind_sum</th>\n",
       "      <th>dx_423_ind_max</th>\n",
       "      <th>dx_423_ind_sum</th>\n",
       "      <th>dx_281_ind_max</th>\n",
       "      <th>dx_281_ind_sum</th>\n",
       "      <th>dx_536_ind_max</th>\n",
       "      <th>dx_536_ind_sum</th>\n",
       "      <th>dx_368_ind_max</th>\n",
       "      <th>dx_368_ind_sum</th>\n",
       "      <th>dx_515_ind_max</th>\n",
       "      <th>dx_515_ind_sum</th>\n",
       "      <th>dx_595_ind_max</th>\n",
       "      <th>dx_595_ind_sum</th>\n",
       "      <th>dx_572_ind_max</th>\n",
       "      <th>dx_572_ind_sum</th>\n",
       "      <th>dx_681_ind_max</th>\n",
       "      <th>dx_681_ind_sum</th>\n",
       "      <th>dx_581_ind_max</th>\n",
       "      <th>dx_581_ind_sum</th>\n",
       "      <th>dx_537_ind_max</th>\n",
       "      <th>dx_537_ind_sum</th>\n",
       "      <th>dx_490_ind_max</th>\n",
       "      <th>dx_490_ind_sum</th>\n",
       "      <th>dx_583_ind_max</th>\n",
       "      <th>dx_583_ind_sum</th>\n",
       "      <th>dx_V46_ind_max</th>\n",
       "      <th>dx_V46_ind_sum</th>\n",
       "      <th>dx_519_ind_max</th>\n",
       "      <th>dx_519_ind_sum</th>\n",
       "      <th>dx_300_ind_max</th>\n",
       "      <th>dx_300_ind_sum</th>\n",
       "      <th>dx_567_ind_max</th>\n",
       "      <th>dx_567_ind_sum</th>\n",
       "      <th>dx_E92_ind_max</th>\n",
       "      <th>dx_E92_ind_sum</th>\n",
       "      <th>dx_V49_ind_max</th>\n",
       "      <th>dx_V49_ind_sum</th>\n",
       "      <th>dx_094_ind_max</th>\n",
       "      <th>dx_094_ind_sum</th>\n",
       "      <th>dx_514_ind_max</th>\n",
       "      <th>dx_514_ind_sum</th>\n",
       "      <th>dx_494_ind_max</th>\n",
       "      <th>dx_494_ind_sum</th>\n",
       "      <th>dx_042_ind_max</th>\n",
       "      <th>dx_042_ind_sum</th>\n",
       "      <th>dx_404_ind_max</th>\n",
       "      <th>dx_404_ind_sum</th>\n",
       "      <th>dx_346_ind_max</th>\n",
       "      <th>dx_346_ind_sum</th>\n",
       "      <th>dx_792_ind_max</th>\n",
       "      <th>dx_792_ind_sum</th>\n",
       "      <th>dx_398_ind_max</th>\n",
       "      <th>dx_398_ind_sum</th>\n",
       "      <th>dx_753_ind_max</th>\n",
       "      <th>dx_753_ind_sum</th>\n",
       "      <th>dx_577_ind_max</th>\n",
       "      <th>dx_577_ind_sum</th>\n",
       "      <th>dx_730_ind_max</th>\n",
       "      <th>dx_730_ind_sum</th>\n",
       "      <th>dx_444_ind_max</th>\n",
       "      <th>dx_444_ind_sum</th>\n",
       "      <th>dx_459_ind_max</th>\n",
       "      <th>dx_459_ind_sum</th>\n",
       "      <th>dx_790_ind_max</th>\n",
       "      <th>dx_790_ind_sum</th>\n",
       "      <th>dx_337_ind_max</th>\n",
       "      <th>dx_337_ind_sum</th>\n",
       "      <th>dx_397_ind_max</th>\n",
       "      <th>dx_397_ind_sum</th>\n",
       "      <th>dx_292_ind_max</th>\n",
       "      <th>dx_292_ind_sum</th>\n",
       "      <th>dx_V42_ind_max</th>\n",
       "      <th>dx_V42_ind_sum</th>\n",
       "      <th>dx_289_ind_max</th>\n",
       "      <th>dx_289_ind_sum</th>\n",
       "      <th>alcohol_history_ind</th>\n",
       "      <th>obesity_history_ind</th>\n",
       "      <th>mh_history_ind</th>\n",
       "      <th>encounter_ct</th>\n",
       "      <th>mb_time_in_hospital</th>\n",
       "      <th>mb_num_lab_procedures_ct</th>\n",
       "      <th>mb_num_procedures_ct</th>\n",
       "      <th>mb_num_medications_ct</th>\n",
       "      <th>mb_number_outpatient_ct</th>\n",
       "      <th>mb_number_emergency_ct</th>\n",
       "      <th>mb_number_inpatient_ct</th>\n",
       "      <th>mb_number_diagnoses_ct</th>\n",
       "      <th>age_encoded</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>250</td>\n",
       "      <td>V27</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DIABETES IN PREG-UNSPEC</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>DELIVER-SINGLE LIVEBORN</td>\n",
       "      <td>285</td>\n",
       "      <td>12794</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>DIABETES IN PREG-UNSPEC</td>\n",
       "      <td>DELIVER-SINGLE LIVEBORN</td>\n",
       "      <td>36015</td>\n",
       "      <td>417</td>\n",
       "      <td>37</td>\n",
       "      <td>(250 648 V27)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "      <td>403</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>INTEST INFEC E COLI NOS</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>MAL HY KID W CR KID I-IV</td>\n",
       "      <td>515</td>\n",
       "      <td>12794</td>\n",
       "      <td>2357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>MAL HY KID W CR KID I-IV</td>\n",
       "      <td>INTEST INFEC E COLI NOS</td>\n",
       "      <td>36015</td>\n",
       "      <td>2261</td>\n",
       "      <td>834</td>\n",
       "      <td>(250 403 8)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>157</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SECONDARY MALIG NEO LUNG</td>\n",
       "      <td>MAL NEO PANCREAS HEAD</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>320</td>\n",
       "      <td>85</td>\n",
       "      <td>17157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>MAL NEO PANCREAS HEAD</td>\n",
       "      <td>SECONDARY MALIG NEO LUNG</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>233</td>\n",
       "      <td>608</td>\n",
       "      <td>189</td>\n",
       "      <td>(157 197 250)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35754</td>\n",
       "      <td>82637451</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>411</td>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Clinic Referral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>6581</td>\n",
       "      <td>2566</td>\n",
       "      <td>17157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>36015</td>\n",
       "      <td>1476</td>\n",
       "      <td>4041</td>\n",
       "      <td>(250 411 414)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55842</td>\n",
       "      <td>84259809</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>411</td>\n",
       "      <td>V45</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Elective</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Clinic Referral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>STATUS CARDC DVCE UNSPCF</td>\n",
       "      <td>6581</td>\n",
       "      <td>2566</td>\n",
       "      <td>1389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>STATUS CARDC DVCE UNSPCF</td>\n",
       "      <td>1650</td>\n",
       "      <td>5936</td>\n",
       "      <td>1698</td>\n",
       "      <td>(411 414 V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr  gender  time_in_hospital  num_lab_procedures  \\\n",
       "0         64410     86047875  Female                 2                  11   \n",
       "1        500364     82442376    Male                 2                  44   \n",
       "2         16680     42519267    Male                 1                  51   \n",
       "3         35754     82637451    Male                 3                  31   \n",
       "4         55842     84259809    Male                 4                  70   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "0               5               13                  2                 0   \n",
       "1               1               16                  0                 0   \n",
       "2               0                8                  0                 0   \n",
       "3               6               16                  0                 0   \n",
       "4               1               21                  0                 0   \n",
       "\n",
       "   number_inpatient diag_1 diag_2 diag_3  number_diagnoses A1Cresult  \\\n",
       "0                 1    648    250    V27                 6       NaN   \n",
       "1                 0      8    250    403                 7       NaN   \n",
       "2                 0    197    157    250                 5       NaN   \n",
       "3                 0    414    411    250                 9       NaN   \n",
       "4                 0    414    411    V45                 7       NaN   \n",
       "\n",
       "  metformin glimepiride glipizide glyburide pioglitazone rosiglitazone  \\\n",
       "0        No          No    Steady        No           No            No   \n",
       "1        No          No        No        No           No            No   \n",
       "2        No          No    Steady        No           No            No   \n",
       "3        No          No        No        No           No            No   \n",
       "4    Steady      Steady        No        No           No            No   \n",
       "\n",
       "  insulin change diabetesMed readmitted admission_type discharge_disposition  \\\n",
       "0      No     No         Yes         NO      Emergency    Discharged to home   \n",
       "1      Up     Ch         Yes         NO      Emergency    Discharged to home   \n",
       "2  Steady     Ch         Yes         NO      Emergency    Discharged to home   \n",
       "3  Steady     No         Yes        >30         Urgent    Discharged to home   \n",
       "4  Steady     Ch         Yes         NO       Elective    Discharged to home   \n",
       "\n",
       "  admission_source  mb_admission_grp_1_ct  mb_admission_grp_2_ct  \\\n",
       "0   Emergency Room                      1                      0   \n",
       "1   Emergency Room                      1                      0   \n",
       "2   Emergency Room                      1                      0   \n",
       "3  Clinic Referral                      0                      0   \n",
       "4  Clinic Referral                      0                      1   \n",
       "\n",
       "   mb_discharge_grp_1_ct  mb_discharge_grp_2_ct  mb_admission_type_ct  \\\n",
       "0                      1                      0                     0   \n",
       "1                      1                      0                     0   \n",
       "2                      1                      0                     0   \n",
       "3                      1                      0                     1   \n",
       "4                      1                      0                     1   \n",
       "\n",
       "   distinct_diag_count               diagnosis_1            diagnosis_2  \\\n",
       "0                    3   DIABETES IN PREG-UNSPEC      DIABETES MELLITUS   \n",
       "1                    3   INTEST INFEC E COLI NOS      DIABETES MELLITUS   \n",
       "2                    3  SECONDARY MALIG NEO LUNG  MAL NEO PANCREAS HEAD   \n",
       "3                    3  COR ATH UNSP VSL NTV/GFT       POST MI SYNDROME   \n",
       "4                    3  COR ATH UNSP VSL NTV/GFT       POST MI SYNDROME   \n",
       "\n",
       "                diagnosis_3  diag_1_freq  diag_2_freq  diag_3_freq  \\\n",
       "0   DELIVER-SINGLE LIVEBORN          285        12794           37   \n",
       "1  MAL HY KID W CR KID I-IV          515        12794         2357   \n",
       "2         DIABETES MELLITUS          320           85        17157   \n",
       "3         DIABETES MELLITUS         6581         2566        17157   \n",
       "4  STATUS CARDC DVCE UNSPCF         6581         2566         1389   \n",
       "\n",
       "   LTIS_38_ind  LTIS_40_ind  LTIS_36_ind  LTIS_320_ind  LTIS_324_ind  \\\n",
       "0            0            0            0             0             0   \n",
       "1            0            0            0             0             0   \n",
       "2            0            0            0             0             0   \n",
       "3            0            0            0             0             0   \n",
       "4            0            0            0             0             0   \n",
       "\n",
       "   CE_410_ind  CE_430_ind  CE_431_ind  CE_415_ind  CE_428_ind  CMN_155_ind  \\\n",
       "0           0           0           0           0           0            0   \n",
       "1           0           0           0           0           0            0   \n",
       "2           0           0           0           0           0            0   \n",
       "3           0           0           0           0           0            0   \n",
       "4           0           0           0           0           0            0   \n",
       "\n",
       "   CMN_162_ind  CMN_191_ind  CMN_197_ind  CMN_199_ind  OF_570_ind  OF_584_ind  \\\n",
       "0            0            0            0            0           0           0   \n",
       "1            0            0            0            0           0           0   \n",
       "2            0            0            0            0           0           0   \n",
       "3            0            0            0            0           0           0   \n",
       "4            0            0            0            0           0           0   \n",
       "\n",
       "   OF_585_ind  OF_277_ind  NBD_331_ind  NBD_340_ind  NBD_780_ind  NBD_852_ind  \\\n",
       "0           0           0            0            0            0            0   \n",
       "1           0           0            0            0            0            0   \n",
       "2           0           0            0            0            0            0   \n",
       "3           0           0            0            0            0            0   \n",
       "4           0           0            0            0            0            0   \n",
       "\n",
       "   STI_806_ind  STI_861_ind  STI_864_ind  STI_958_ind  OCC_250_ind  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            1   \n",
       "3            0            0            0            0            1   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   OCC_995_ind  OCC_986_ind  OCC_989_ind  diagnosis_combo_frequency  \\\n",
       "0            0            0            0                         15   \n",
       "1            0            0            0                          5   \n",
       "2            0            0            0                         14   \n",
       "3            0            0            0                        582   \n",
       "4            0            0            0                        104   \n",
       "\n",
       "           sorted_diag_1             sorted_diag_2             sorted_diag_3  \\\n",
       "0      DIABETES MELLITUS   DIABETES IN PREG-UNSPEC   DELIVER-SINGLE LIVEBORN   \n",
       "1      DIABETES MELLITUS  MAL HY KID W CR KID I-IV   INTEST INFEC E COLI NOS   \n",
       "2  MAL NEO PANCREAS HEAD  SECONDARY MALIG NEO LUNG         DIABETES MELLITUS   \n",
       "3      DIABETES MELLITUS          POST MI SYNDROME  COR ATH UNSP VSL NTV/GFT   \n",
       "4       POST MI SYNDROME  COR ATH UNSP VSL NTV/GFT  STATUS CARDC DVCE UNSPCF   \n",
       "\n",
       "   sorted_diag_1_frequency  sorted_diag_2_frequency  sorted_diag_3_frequency  \\\n",
       "0                    36015                      417                       37   \n",
       "1                    36015                     2261                      834   \n",
       "2                      233                      608                      189   \n",
       "3                    36015                     1476                     4041   \n",
       "4                     1650                     5936                     1698   \n",
       "\n",
       "  diagnosis_combo_string  is_high_risk_combo  dx_428_ind_max  dx_428_ind_sum  \\\n",
       "0          (250 648 V27)                   0               0               0   \n",
       "1            (250 403 8)                   0               0               0   \n",
       "2          (157 197 250)                   0               0               0   \n",
       "3          (250 411 414)                   0               0               0   \n",
       "4          (411 414 V45)                   0               0               0   \n",
       "\n",
       "   dx_403_ind_max  dx_403_ind_sum  dx_707_ind_max  dx_707_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               1               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_585_ind_max  dx_585_ind_sum  dx_491_ind_max  dx_491_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_396_ind_max  dx_396_ind_sum  dx_440_ind_max  dx_440_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_453_ind_max  dx_453_ind_sum  dx_571_ind_max  dx_571_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_284_ind_max  dx_284_ind_sum  dx_304_ind_max  dx_304_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_482_ind_max  dx_482_ind_sum  dx_150_ind_max  dx_150_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_282_ind_max  dx_282_ind_sum  dx_332_ind_max  dx_332_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_443_ind_max  dx_443_ind_sum  dx_719_ind_max  dx_719_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_423_ind_max  dx_423_ind_sum  dx_281_ind_max  dx_281_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_536_ind_max  dx_536_ind_sum  dx_368_ind_max  dx_368_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_515_ind_max  dx_515_ind_sum  dx_595_ind_max  dx_595_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_572_ind_max  dx_572_ind_sum  dx_681_ind_max  dx_681_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_581_ind_max  dx_581_ind_sum  dx_537_ind_max  dx_537_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_490_ind_max  dx_490_ind_sum  dx_583_ind_max  dx_583_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_V46_ind_max  dx_V46_ind_sum  dx_519_ind_max  dx_519_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_300_ind_max  dx_300_ind_sum  dx_567_ind_max  dx_567_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_E92_ind_max  dx_E92_ind_sum  dx_V49_ind_max  dx_V49_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_094_ind_max  dx_094_ind_sum  dx_514_ind_max  dx_514_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_494_ind_max  dx_494_ind_sum  dx_042_ind_max  dx_042_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_404_ind_max  dx_404_ind_sum  dx_346_ind_max  dx_346_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_792_ind_max  dx_792_ind_sum  dx_398_ind_max  dx_398_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_753_ind_max  dx_753_ind_sum  dx_577_ind_max  dx_577_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_730_ind_max  dx_730_ind_sum  dx_444_ind_max  dx_444_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_459_ind_max  dx_459_ind_sum  dx_790_ind_max  dx_790_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_337_ind_max  dx_337_ind_sum  dx_397_ind_max  dx_397_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_292_ind_max  dx_292_ind_sum  dx_V42_ind_max  dx_V42_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_289_ind_max  dx_289_ind_sum  alcohol_history_ind  obesity_history_ind  \\\n",
       "0               0               0                    0                    0   \n",
       "1               0               0                    0                    0   \n",
       "2               0               0                    0                    0   \n",
       "3               0               0                    0                    0   \n",
       "4               0               0                    0                    0   \n",
       "\n",
       "   mh_history_ind  encounter_ct  mb_time_in_hospital  \\\n",
       "0               0             1                    2   \n",
       "1               0             1                    2   \n",
       "2               0             1                    1   \n",
       "3               0             1                    3   \n",
       "4               0             1                    4   \n",
       "\n",
       "   mb_num_lab_procedures_ct  mb_num_procedures_ct  mb_num_medications_ct  \\\n",
       "0                        11                     5                     13   \n",
       "1                        44                     1                     16   \n",
       "2                        51                     0                      8   \n",
       "3                        31                     6                     16   \n",
       "4                        70                     1                     21   \n",
       "\n",
       "   mb_number_outpatient_ct  mb_number_emergency_ct  mb_number_inpatient_ct  \\\n",
       "0                        2                       0                       1   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "\n",
       "   mb_number_diagnoses_ct  age_encoded  dummy  \n",
       "0                       6          1.0      1  \n",
       "1                       7          2.0      1  \n",
       "2                       5          3.0      1  \n",
       "3                       9          4.0      1  \n",
       "4                       7          5.0      1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "# The data was preprocessed in the data_preprocessing.ipynb notebook\n",
    "try:\n",
    "    data = pd.read_csv('../../dataPreprocessing/medical_data.csv')\n",
    "except FileNotFoundError:\n",
    "    data = pd.read_pickle('../../dataPreprocessing/medical_data.pkl')\n",
    "\n",
    "# These columns are derived from the target variable ('readmitted') and must be removed.\n",
    "leaky_features = ['mb_readmitted_lt30_ct', 'mb_readmitted_gt30_ct', 'mb_readmitted_no_ct', 'readmitted_ind']\n",
    "data.drop(columns=[col for col in leaky_features if col in data.columns], inplace=True, errors='ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Data head:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa19fb1",
   "metadata": {},
   "source": [
    "## Data Preparation and Preprocessing Strategy\n",
    "\n",
    "A critical prerequisite for building an effective deep learning model is a robust and well-defined data preprocessing pipeline. Our strategy is designed to handle the mixed data types present in the dataset (numerical, low-cardinality categorical, and high-cardinality categorical) and prepare them for their respective model branches.\n",
    "\n",
    "The process involves the following key steps:\n",
    "\n",
    "1.  **Feature and Target Definition**: We first define our target variable, `readmitted_binary`, and isolate the features that will be used for prediction.\n",
    "2.  **Feature Segregation**: We programmatically separate the features into three distinct groups based on their data type and cardinality (the number of unique values).\n",
    "3.  **Train-Test Split**: The data is split into training and testing sets *before* any transformations are fitted. This is a crucial step to prevent data leakage and ensure our final evaluation is unbiased.\n",
    "4.  **Unified Preprocessing Pipeline**: We use Scikit-learn's `ColumnTransformer` to apply the correct transformation to each feature group in a single, unified step:\n",
    "    *   **Numerical Features**: These are scaled using `StandardScaler` to normalize their range, which helps the model converge more efficiently.\n",
    "    *   **Low-Cardinality Categorical Features**: These are transformed using `OneHotEncoder`, creating a binary column for each category. This is suitable for features with a small number of unique values.\n",
    "    -   **High-Cardinality Categorical Features**: These are converted into unique integers using `OrdinalEncoder`. This is not for establishing order, but as a necessary step to prepare these features for the subsequent `Embedding` layers in our neural network, which will learn a meaningful vector representation for each integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "594041a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable created.\n",
      "readmitted_binary\n",
      "0    42307\n",
      "1    35742\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The target variable is 'readmitted'. We'll convert this into a binary classification problem:\n",
    "# 1 if readmitted (value is '<30' or '>30'), 0 otherwise (value is 'NO').\n",
    "if 'readmitted' in data.columns:\n",
    "    data['readmitted_binary'] = data['readmitted'].apply(lambda x: 1 if x in ['<30', '>30'] else 0)\n",
    "    target = 'readmitted_binary'\n",
    "    \n",
    "    # Drop original readmitted columns and patient_nbr as it's an identifier\n",
    "    features = data.drop(columns=[target, 'readmitted', 'patient_nbr'], errors='ignore')\n",
    "    y = data[target]\n",
    "    X = features\n",
    "    \n",
    "    print(\"Target variable created.\")\n",
    "    print(y.value_counts())\n",
    "else:\n",
    "    print(\"Target column 'readmitted' not found. Please define the target variable.\")\n",
    "    # As a placeholder:\n",
    "    X, y = None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79acae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: 176\n",
      "Low-cardinality categorical features (to be one-hot encoded): 14\n",
      "High-cardinality categorical features (to be embedded): 10\n",
      " -> High-cardinality features: ['diag_1', 'diag_2', 'diag_3', 'diagnosis_1', 'diagnosis_2', 'diagnosis_3', 'sorted_diag_1', 'sorted_diag_2', 'sorted_diag_3', 'diagnosis_combo_string']\n",
      "\n",
      "Data split into training and testing sets.\n",
      "X_train shape: (62439, 200)\n",
      "X_test shape: (15610, 200)\n"
     ]
    }
   ],
   "source": [
    "if X is not None:\n",
    "    # Identify numerical and categorical features\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # Define a threshold for high cardinality\n",
    "    CARDINALITY_THRESHOLD = 50\n",
    "    \n",
    "    # Separate categorical features into low and high cardinality\n",
    "    high_cardinality_features = [col for col in categorical_features if X[col].nunique() > CARDINALITY_THRESHOLD]\n",
    "    low_cardinality_features = [col for col in categorical_features if X[col].nunique() <= CARDINALITY_THRESHOLD]\n",
    "\n",
    "    print(f\"Numerical features: {len(numerical_features)}\")\n",
    "    print(f\"Low-cardinality categorical features (to be one-hot encoded): {len(low_cardinality_features)}\")\n",
    "    print(f\"High-cardinality categorical features (to be embedded): {len(high_cardinality_features)}\")\n",
    "    print(f\" -> High-cardinality features: {high_cardinality_features}\")\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    print(\"\\nData split into training and testing sets.\")\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be1082ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "Processed training data shape: (62439, 268)\n",
      "Processed testing data shape: (15610, 268)\n"
     ]
    }
   ],
   "source": [
    "if X is not None:\n",
    "    # Ensure all categorical columns are strings to avoid mixed-type errors\n",
    "    for col in low_cardinality_features + high_cardinality_features:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col] = X_train[col].astype(str)\n",
    "            X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "    # Create transformers for each feature type\n",
    "    numeric_transformer = StandardScaler()\n",
    "    low_card_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    high_card_transformer = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "    # Create a single preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_features),\n",
    "            ('cat_low', low_card_transformer, low_cardinality_features),\n",
    "            ('cat_high', high_card_transformer, high_cardinality_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Apply the preprocessing\n",
    "    # The preprocessor is FIT ONLY on the training data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    # It is then used to TRANSFORM both the training and test data\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n",
    "    print(\"Processed training data shape:\", X_train_processed.shape)\n",
    "    print(\"Processed testing data shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0896db5",
   "metadata": {},
   "source": [
    "## Model Architecture and Design\n",
    "\n",
    "To effectively handle the diverse types of data in our dataset, we have designed a hybrid neural network using the Keras Functional API. This flexible approach allows us to create a multi-branch model where different kinds of features are processed by specialized layers best suited for their nature. The outputs of these branches are then merged to make a final, unified prediction.\n",
    "\n",
    "The model consists of the following key components:\n",
    "\n",
    "### 1. Unified Input Layer\n",
    "A single `Input` layer serves as the entry point for the entire preprocessed feature vector. This vector contains the scaled numerical features, the one-hot encoded low-cardinality features, and the integer-encoded high-cardinality features, all concatenated together.\n",
    "\n",
    "### 2. Branch 1: CNN for Numerical and Low-Cardinality Features\n",
    "This branch is designed to process the continuous numerical data and the one-hot encoded categorical data. It uses a 1D Convolutional Neural Network (CNN) to learn spatial hierarchies and patterns within this feature set.\n",
    "*   **Slicing (`Lambda`):** A `Lambda` layer first slices the main input tensor to isolate only the numerical and one-hot encoded columns.\n",
    "*   **Reshaping:** The sliced data is reshaped into a 3D tensor, which is the required input format for a `Conv1D` layer.\n",
    "*   **Convolution (`Conv1D`):** A 1D convolutional layer scans the features to identify local patterns.\n",
    "*   **Pooling (`MaxPooling1D`):** A max-pooling layer downsamples the output, making the learned patterns more robust.\n",
    "*   **Flattening:** The pooled feature map is flattened into a 1D vector to be passed to the final classification layers.\n",
    "\n",
    "### 3. Branch 2: Embeddings for High-Cardinality Features\n",
    "This branch is dedicated to handling the high-cardinality categorical features, which are not suitable for one-hot encoding.\n",
    "*   **Slicing (`Lambda`):** For each high-cardinality feature, a `Lambda` layer slices the main input tensor to extract its specific integer-encoded value.\n",
    "*   **Embedding (`Embedding`):** An `Embedding` layer converts each integer into a dense, low-dimensional vector. This layer learns a meaningful representation for each category, capturing semantic relationships between them in a way that one-hot encoding cannot.\n",
    "*   **Flattening:** The resulting embedding vectors are flattened to prepare them for merging.\n",
    "\n",
    "### 4. Merging and Final Classification\n",
    "*   **Concatenation:** The output vector from the CNN branch is concatenated with the output vectors from all the embedding branches, creating a single, comprehensive feature vector.\n",
    "*   **Classification Head:** This final, fully-connected part of the network makes the prediction:\n",
    "    *   A `Dense` layer with a `relu` activation function learns complex, non-linear combinations of the merged features.\n",
    "    *   A `Dropout` layer is applied for regularization to prevent overfitting.\n",
    "    *   The final `Dense` output layer consists of a single neuron with a `sigmoid` activation function, which outputs a probability score between 0 and 1 for the binary classification task (readmitted or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb75cc",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna\n",
    "\n",
    "To find the optimal configuration for our model, we employ a systematic hyperparameter tuning process using the Optuna framework. This process is divided into two key functions:\n",
    "\n",
    "1.  **`build_model(params)`**: This is a centralized factory function that constructs and compiles our hybrid CNN-Embedding model. It accepts a `params` dictionary, allowing us to dynamically create different versions of the model architecture. This approach ensures our model definition is consistent and easy to maintain.\n",
    "\n",
    "2.  **`objective(trial)`**: This is the core function that Optuna interacts with. For each trial, it performs the following steps:\n",
    "    *   **Defines the Search Space**: It asks Optuna to suggest a new set of hyperparameters (e.g., `learning_rate`, `cnn_filters`, `dropout_rate`).\n",
    "    *   **Builds the Model**: It passes the suggested hyperparameters to our `build_model` function.\n",
    "    *   **Trains and Validates**: It trains the model on a portion of the training data, using a `validation_split` and an `EarlyStopping` callback. This is crucial for getting an unbiased performance estimate and preventing overfitting within each trial.\n",
    "    *   **Stores Results**: The training history is saved to the trial's attributes for later analysis.\n",
    "    *   **Returns the Score**: It returns the best validation loss achieved during the trial, which Optuna then uses to guide its search for the next trial.\n",
    "\n",
    "The `study.optimize()` command executes this process for a set number of trials, intelligently exploring the hyperparameter space to find the combination that minimizes validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0b7a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):    \n",
    "    # --- 1. Get data shape information from the preprocessor ---\n",
    "    num_ohe_features = preprocessor.named_transformers_['cat_low'].get_feature_names_out().shape[0]\n",
    "    ohe_start_idx = len(numerical_features)\n",
    "    embed_start_idx = ohe_start_idx + num_ohe_features\n",
    "    \n",
    "    input_layer = Input(shape=(X_train_processed.shape[1],), name='main_input')\n",
    "\n",
    "    # --- 2. CNN Branch for numerical and one-hot encoded features ---\n",
    "    cnn_input_data = Lambda(lambda x: x[:, :embed_start_idx])(input_layer)\n",
    "    reshaped_cnn_data = Reshape((embed_start_idx, 1))(cnn_input_data)\n",
    "    conv1d = Conv1D(filters=params['cnn_filters'], kernel_size=3, activation='relu')(reshaped_cnn_data)\n",
    "    pool1d = MaxPooling1D(pool_size=2)(conv1d)\n",
    "    flatten_cnn = Flatten()(pool1d)\n",
    "\n",
    "    # --- 3. Embedding Branch for high-cardinality features ---\n",
    "    embedding_layers = []\n",
    "    for i, col_name in enumerate(high_cardinality_features):\n",
    "        category_input = Lambda(lambda x: x[:, embed_start_idx + i])(input_layer)\n",
    "        vocab_size = len(preprocessor.named_transformers_['cat_high'].categories_[i])\n",
    "        embedding = Embedding(input_dim=vocab_size, output_dim=params['embedding_dim'])(category_input)\n",
    "        flatten_embed = Flatten()(embedding)\n",
    "        embedding_layers.append(flatten_embed)\n",
    "\n",
    "    # --- 4. Merge branches and add final classification layers ---\n",
    "    merged = concatenate([flatten_cnn] + embedding_layers)\n",
    "    dense1 = Dense(units=params['dense_units'], activation='relu')(merged)\n",
    "    dropout1 = Dropout(rate=params['dropout_rate'])(dense1)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dropout1)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    # --- 5. Compile the model ---\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=params['learning_rate']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c27ea29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-27 19:37:01,246] A new study created in memory with name: no-name-044d77b1-f0a3-4d20-bf30-cae063916c93\n",
      "[I 2025-06-27 19:37:16,973] Trial 0 finished with value: 0.47066953778266907 and parameters: {'learning_rate': 0.0008486880557047253, 'cnn_filters': 32, 'embedding_dim': 16, 'dense_units': 32, 'dropout_rate': 0.34821253448517475}. Best is trial 0 with value: 0.47066953778266907.\n",
      "[I 2025-06-27 19:37:30,404] Trial 1 finished with value: 0.46623605489730835 and parameters: {'learning_rate': 0.004101339454027261, 'cnn_filters': 32, 'embedding_dim': 32, 'dense_units': 32, 'dropout_rate': 0.3129523303110386}. Best is trial 1 with value: 0.46623605489730835.\n",
      "[I 2025-06-27 19:37:44,957] Trial 2 finished with value: 0.476951539516449 and parameters: {'learning_rate': 0.0022960642703881823, 'cnn_filters': 32, 'embedding_dim': 25, 'dense_units': 32, 'dropout_rate': 0.4693922432709162}. Best is trial 1 with value: 0.46623605489730835.\n",
      "[I 2025-06-27 19:37:59,943] Trial 3 finished with value: 0.4732448160648346 and parameters: {'learning_rate': 0.0015147738011436875, 'cnn_filters': 32, 'embedding_dim': 13, 'dense_units': 128, 'dropout_rate': 0.3353293895085143}. Best is trial 1 with value: 0.46623605489730835.\n",
      "[I 2025-06-27 19:38:12,083] Trial 4 finished with value: 0.4790436029434204 and parameters: {'learning_rate': 0.0036268080217899895, 'cnn_filters': 64, 'embedding_dim': 12, 'dense_units': 64, 'dropout_rate': 0.6056257820934088}. Best is trial 1 with value: 0.46623605489730835.\n",
      "[I 2025-06-27 19:38:26,859] Trial 5 finished with value: 0.48615092039108276 and parameters: {'learning_rate': 0.0013743272041115474, 'cnn_filters': 32, 'embedding_dim': 27, 'dense_units': 128, 'dropout_rate': 0.6809402912956438}. Best is trial 1 with value: 0.46623605489730835.\n",
      "[I 2025-06-27 19:38:45,866] Trial 6 finished with value: 0.4597143232822418 and parameters: {'learning_rate': 0.0001989046343705304, 'cnn_filters': 64, 'embedding_dim': 16, 'dense_units': 32, 'dropout_rate': 0.44405812411616397}. Best is trial 6 with value: 0.4597143232822418.\n",
      "[I 2025-06-27 19:38:59,622] Trial 7 finished with value: 0.483283132314682 and parameters: {'learning_rate': 0.001572279223321008, 'cnn_filters': 16, 'embedding_dim': 15, 'dense_units': 64, 'dropout_rate': 0.5875788063584082}. Best is trial 6 with value: 0.4597143232822418.\n",
      "[I 2025-06-27 19:39:14,625] Trial 8 finished with value: 0.4790739417076111 and parameters: {'learning_rate': 0.000312890294817093, 'cnn_filters': 16, 'embedding_dim': 24, 'dense_units': 64, 'dropout_rate': 0.6529253781988288}. Best is trial 6 with value: 0.4597143232822418.\n",
      "[I 2025-06-27 19:39:28,649] Trial 9 finished with value: 0.4703691303730011 and parameters: {'learning_rate': 0.004721287096113509, 'cnn_filters': 64, 'embedding_dim': 29, 'dense_units': 128, 'dropout_rate': 0.3881220028655834}. Best is trial 6 with value: 0.4597143232822418.\n",
      "[I 2025-06-27 19:39:59,369] Trial 10 finished with value: 0.4501683712005615 and parameters: {'learning_rate': 0.00010243349964040609, 'cnn_filters': 64, 'embedding_dim': 8, 'dense_units': 32, 'dropout_rate': 0.45838349298252457}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:40:29,663] Trial 11 finished with value: 0.4514959454536438 and parameters: {'learning_rate': 0.00010078509385951321, 'cnn_filters': 64, 'embedding_dim': 8, 'dense_units': 32, 'dropout_rate': 0.4567781222064529}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:41:06,893] Trial 12 finished with value: 0.4597141444683075 and parameters: {'learning_rate': 0.00010450596891142537, 'cnn_filters': 64, 'embedding_dim': 8, 'dense_units': 32, 'dropout_rate': 0.517264264994337}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:41:42,216] Trial 13 finished with value: 0.46046939492225647 and parameters: {'learning_rate': 0.00010196669866190431, 'cnn_filters': 64, 'embedding_dim': 9, 'dense_units': 32, 'dropout_rate': 0.5235160671375568}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:41:56,245] Trial 14 finished with value: 0.46506235003471375 and parameters: {'learning_rate': 0.0005239795537109726, 'cnn_filters': 64, 'embedding_dim': 20, 'dense_units': 32, 'dropout_rate': 0.4154278369603819}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:42:14,860] Trial 15 finished with value: 0.4588300883769989 and parameters: {'learning_rate': 0.0002504484997085773, 'cnn_filters': 64, 'embedding_dim': 11, 'dense_units': 32, 'dropout_rate': 0.48365852363467315}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:42:36,624] Trial 16 finished with value: 0.46319642663002014 and parameters: {'learning_rate': 0.000161761647399539, 'cnn_filters': 64, 'embedding_dim': 20, 'dense_units': 32, 'dropout_rate': 0.5727840890666756}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:42:52,558] Trial 17 finished with value: 0.4664686620235443 and parameters: {'learning_rate': 0.0004160980317105762, 'cnn_filters': 16, 'embedding_dim': 8, 'dense_units': 32, 'dropout_rate': 0.3840395401903739}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:43:07,564] Trial 18 finished with value: 0.4731244444847107 and parameters: {'learning_rate': 0.008928230517079782, 'cnn_filters': 64, 'embedding_dim': 11, 'dense_units': 128, 'dropout_rate': 0.5366196595337416}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:43:24,270] Trial 19 finished with value: 0.4644840657711029 and parameters: {'learning_rate': 0.0006647570535320688, 'cnn_filters': 64, 'embedding_dim': 14, 'dense_units': 64, 'dropout_rate': 0.429797816842738}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:43:47,723] Trial 20 finished with value: 0.4749542772769928 and parameters: {'learning_rate': 0.00014812494603987892, 'cnn_filters': 16, 'embedding_dim': 18, 'dense_units': 32, 'dropout_rate': 0.4658428270664245}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:44:07,555] Trial 21 finished with value: 0.4592788815498352 and parameters: {'learning_rate': 0.000228059656834795, 'cnn_filters': 64, 'embedding_dim': 10, 'dense_units': 32, 'dropout_rate': 0.482449244636037}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:44:24,406] Trial 22 finished with value: 0.46553367376327515 and parameters: {'learning_rate': 0.00030586618100735224, 'cnn_filters': 64, 'embedding_dim': 11, 'dense_units': 32, 'dropout_rate': 0.48929516485475044}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:44:54,629] Trial 23 finished with value: 0.4555671811103821 and parameters: {'learning_rate': 0.0001398725497859633, 'cnn_filters': 64, 'embedding_dim': 8, 'dense_units': 32, 'dropout_rate': 0.5474970211530513}. Best is trial 10 with value: 0.4501683712005615.\n",
      "[I 2025-06-27 19:45:19,337] Trial 24 finished with value: 0.4536772072315216 and parameters: {'learning_rate': 0.00012622285298320986, 'cnn_filters': 64, 'embedding_dim': 8, 'dense_units': 32, 'dropout_rate': 0.5380567510878801}. Best is trial 10 with value: 0.4501683712005615.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (val_loss): 0.4501683712005615\n",
      "  Params: \n",
      "    learning_rate: 0.00010243349964040609\n",
      "    cnn_filters: 64\n",
      "    embedding_dim: 8\n",
      "    dense_units: 32\n",
      "    dropout_rate: 0.45838349298252457\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # --- 1. Define Hyperparameter Search Space ---\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "        'cnn_filters': trial.suggest_categorical('cnn_filters', [16, 32, 64]),\n",
    "        'embedding_dim': trial.suggest_int('embedding_dim', 8, 32),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [32, 64, 128]),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.3, 0.7)\n",
    "    }\n",
    "\n",
    "    # --- 2. Build and compile the model ---\n",
    "    model = build_model(params)\n",
    "    \n",
    "    # --- 3. Train the Model ---\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        X_train_processed, y_train,\n",
    "        epochs=20,\n",
    "        batch_size=128,\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    # --- 4. Evaluate and Return the Metric to Optimize ---\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    # Store the history in the trial to access it later\n",
    "    trial.set_user_attr(\"history\", history.history) \n",
    "    return val_loss\n",
    "\n",
    "# --- Run the Optuna Study ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=25) # Run 25 trials to find the best hyperparameters\n",
    "\n",
    "# --- Print the Best Results ---\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"  Value (val_loss): {best_trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e06d9",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Final Model\n",
    "\n",
    "After the Optuna study has identified the most promising set of hyperparameters, the final step is to train a definitive model and evaluate its performance on the unseen test set. This process ensures we are using our data and the insights from tuning as effectively as possible.\n",
    "\n",
    "The workflow is as follows:\n",
    "\n",
    "1.  **Retrieve Best Hyperparameters**: We extract the `best_params` dictionary from the completed Optuna study. These are the parameters that yielded the lowest validation loss.\n",
    "\n",
    "2.  **Determine Optimal Training Duration**: To prevent the overfitting we observed previously, we do not train for a fixed number of epochs. Instead, we inspect the saved `history` from the best trial and find the exact epoch (`optimal_epochs`) at which the validation loss was at its minimum. This is the ideal training duration for our model architecture.\n",
    "\n",
    "3.  **Build and Train the Final Model**: We call the `build_model` function one last time using the `best_params`. Then, we train this model on the **entire training dataset** for the `optimal_epochs` we just determined. No validation set is used here, as all model-selection decisions have already been made. This step ensures the final model learns from all available training data.\n",
    "\n",
    "4.  **Final Evaluation**: The fully trained model is evaluated against the completely separate test set. The resulting test accuracy and loss provide the most reliable measure of how the model is expected to perform on new, real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3d3a896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_55\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_55\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ main_input          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">268</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_561 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ reshape_51          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ lambda_561[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv1d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> ‚îÇ reshape_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_562 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_563 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_564 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_565 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_566 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_567 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_568 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_569 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_570 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_571 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling1d_51    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ conv1d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_510       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,208</span> ‚îÇ lambda_562[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_511       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,032</span> ‚îÇ lambda_563[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_512       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,208</span> ‚îÇ lambda_564[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_513       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,208</span> ‚îÇ lambda_565[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_514       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,032</span> ‚îÇ lambda_566[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_515       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,208</span> ‚îÇ lambda_567[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_516       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,176</span> ‚îÇ lambda_568[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_517       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,000</span> ‚îÇ lambda_569[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_518       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,928</span> ‚îÇ lambda_570[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_519       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">220,688</span> ‚îÇ lambda_571[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_561         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ max_pooling1d_51‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_562         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_510[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_563         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_511[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_564         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_512[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_565         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_513[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_566         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_514[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_567         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_515[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_568         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_516[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_569         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_517[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_570         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_518[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_571         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_519[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ concatenate_51      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8272</span>)      ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ flatten_561[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       ‚îÇ                   ‚îÇ            ‚îÇ flatten_562[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_563[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_564[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_565[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_566[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_567[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_568[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_569[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_570[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_571[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">264,736</span> ‚îÇ concatenate_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_51          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense_102[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> ‚îÇ dropout_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ main_input          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m268\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_561 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ reshape_51          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m, \u001b[38;5;34m1\u001b[0m)    ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ lambda_561[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mReshape\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv1d_51 (\u001b[38;5;33mConv1D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   ‚îÇ        \u001b[38;5;34m256\u001b[0m ‚îÇ reshape_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_562 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_563 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_564 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_565 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_566 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_567 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_568 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_569 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_570 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_571 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling1d_51    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ conv1d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_510       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m5,208\u001b[0m ‚îÇ lambda_562[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_511       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m5,032\u001b[0m ‚îÇ lambda_563[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_512       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m5,208\u001b[0m ‚îÇ lambda_564[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_513       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m5,208\u001b[0m ‚îÇ lambda_565[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_514       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m5,032\u001b[0m ‚îÇ lambda_566[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_515       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m5,208\u001b[0m ‚îÇ lambda_567[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_516       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m4,176\u001b[0m ‚îÇ lambda_568[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_517       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m5,000\u001b[0m ‚îÇ lambda_569[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_518       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ      \u001b[38;5;34m4,928\u001b[0m ‚îÇ lambda_570[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_519       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ    \u001b[38;5;34m220,688\u001b[0m ‚îÇ lambda_571[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_561         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ max_pooling1d_51‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_562         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_510[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_563         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_511[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_564         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_512[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_565         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_513[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_566         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_514[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_567         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_515[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_568         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_516[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_569         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_517[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_570         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_518[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_571         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_519[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ concatenate_51      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8272\u001b[0m)      ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ flatten_561[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mConcatenate\u001b[0m)       ‚îÇ                   ‚îÇ            ‚îÇ flatten_562[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_563[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_564[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_565[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_566[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_567[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_568[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_569[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_570[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_571[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_102 (\u001b[38;5;33mDense\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        ‚îÇ    \u001b[38;5;34m264,736\u001b[0m ‚îÇ concatenate_51[\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_51          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense_102[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mDropout\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_103 (\u001b[38;5;33mDense\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         ‚îÇ         \u001b[38;5;34m33\u001b[0m ‚îÇ dropout_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,713</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m530,713\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,713</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m530,713\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal number of epochs found: 10\n",
      "Training final model...\n",
      "Epoch 1/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7112 - loss: 0.5779\n",
      "Epoch 2/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7602 - loss: 0.5167\n",
      "Epoch 3/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.5004\n",
      "Epoch 4/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.4886\n",
      "Epoch 5/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7789 - loss: 0.4802\n",
      "Epoch 6/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.4720\n",
      "Epoch 7/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 0.4647\n",
      "Epoch 8/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.4582\n",
      "Epoch 9/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.4475\n",
      "Epoch 10/10\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8024 - loss: 0.4357\n",
      "\n",
      "Final Test Loss: 0.4544\n",
      "Final Test Accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Get the best hyperparameters from the study ---\n",
    "best_params = study.best_params\n",
    "\n",
    "# --- 2. Build the final model with the best hyperparameters ---\n",
    "final_model = build_model(best_params)\n",
    "final_model.summary()\n",
    "\n",
    "# --- 3. Determine the optimal number of epochs from the best trial ---\n",
    "# Get the history from the best trial\n",
    "best_trial_history = study.best_trial.user_attrs[\"history\"]\n",
    "# Find the epoch with the lowest validation loss\n",
    "optimal_epochs = np.argmin(best_trial_history['val_loss']) + 1\n",
    "print(f\"\\nOptimal number of epochs found: {optimal_epochs}\")\n",
    "\n",
    "# --- 4. Train the final model on the full training data for the optimal number of epochs ---\n",
    "print(\"Training final model...\")\n",
    "history = final_model.fit(\n",
    "    X_train_processed, y_train,\n",
    "    epochs=optimal_epochs, # Use the optimal number of epochs\n",
    "    batch_size=best_params.get('batch_size', 128), # Use batch size from params if available\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- 5. Evaluate the final model on the test set ---\n",
    "loss, accuracy = final_model.evaluate(X_test_processed, y_test, verbose=0)\n",
    "print(f\"\\nFinal Test Loss: {loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
