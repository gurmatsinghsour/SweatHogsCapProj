{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbb1529",
   "metadata": {},
   "source": [
    "# Predicting Patient Readmission with a Hybrid Deep Learning Model\n",
    "\n",
    "### Project Objective\n",
    "This notebook develops and optimizes a deep learning model to predict the likelihood of a patient being readmitted to a hospital. The goal is to create a robust, high-performing model by leveraging a hybrid architecture and systematic hyperparameter tuning.\n",
    "\n",
    "### Methodology\n",
    "The core of this solution is a hybrid neural network that processes different types of features using specialized layers:\n",
    "*   **1D Convolutional Neural Network (CNN):** Used to extract spatial patterns from the numerical and one-hot encoded categorical features.\n",
    "*   **Entity Embeddings:** Used to create dense, meaningful vector representations of high-cardinality categorical features, capturing complex relationships between their categories.\n",
    "*   **Optuna Hyperparameter Tuning:** We employ the Optuna framework to systematically search for the optimal model configuration, including learning rate, layer sizes, and dropout rates, ensuring a data-driven approach to model design.\n",
    "*   **Robust Evaluation:** The model is trained using a rigorous process that prevents overfitting by identifying the optimal training duration and is evaluated on a completely unseen test set to provide a reliable measure of its real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5ed437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 21:46:17.708235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751334377.804023     854 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751334377.830186     854 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751334378.046234     854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751334378.046295     854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751334378.046298     854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751334378.046300     854 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-30 21:46:18.068137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/paul/SweatHogsCapProj/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Embedding, concatenate, Reshape, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5e5f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ GPU(s) detected!\n",
      " - PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "TensorFlow will use the GPU by default when available.\n"
     ]
    }
   ],
   "source": [
    "# List physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"üöÄ GPU(s) detected!\")\n",
    "    for gpu in gpus:\n",
    "        print(f\" - {gpu}\")\n",
    "    print(\"TensorFlow will use the GPU by default when available.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Using CPU only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cd8353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_854/1422035621.py:4: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../../dataPreprocessing/medical_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (78049, 202)\n",
      "Data head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>gender</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>discharge_disposition</th>\n",
       "      <th>admission_source</th>\n",
       "      <th>mb_admission_grp_1_ct</th>\n",
       "      <th>mb_admission_grp_2_ct</th>\n",
       "      <th>mb_discharge_grp_1_ct</th>\n",
       "      <th>mb_discharge_grp_2_ct</th>\n",
       "      <th>mb_admission_type_ct</th>\n",
       "      <th>distinct_diag_count</th>\n",
       "      <th>diagnosis_1</th>\n",
       "      <th>diagnosis_2</th>\n",
       "      <th>diagnosis_3</th>\n",
       "      <th>diag_1_freq</th>\n",
       "      <th>diag_2_freq</th>\n",
       "      <th>diag_3_freq</th>\n",
       "      <th>LTIS_38_ind</th>\n",
       "      <th>LTIS_40_ind</th>\n",
       "      <th>LTIS_36_ind</th>\n",
       "      <th>LTIS_320_ind</th>\n",
       "      <th>LTIS_324_ind</th>\n",
       "      <th>CE_410_ind</th>\n",
       "      <th>CE_430_ind</th>\n",
       "      <th>CE_431_ind</th>\n",
       "      <th>CE_415_ind</th>\n",
       "      <th>CE_428_ind</th>\n",
       "      <th>CMN_155_ind</th>\n",
       "      <th>CMN_162_ind</th>\n",
       "      <th>CMN_191_ind</th>\n",
       "      <th>CMN_197_ind</th>\n",
       "      <th>CMN_199_ind</th>\n",
       "      <th>OF_570_ind</th>\n",
       "      <th>OF_584_ind</th>\n",
       "      <th>OF_585_ind</th>\n",
       "      <th>OF_277_ind</th>\n",
       "      <th>NBD_331_ind</th>\n",
       "      <th>NBD_340_ind</th>\n",
       "      <th>NBD_780_ind</th>\n",
       "      <th>NBD_852_ind</th>\n",
       "      <th>STI_806_ind</th>\n",
       "      <th>STI_861_ind</th>\n",
       "      <th>STI_864_ind</th>\n",
       "      <th>STI_958_ind</th>\n",
       "      <th>OCC_250_ind</th>\n",
       "      <th>OCC_995_ind</th>\n",
       "      <th>OCC_986_ind</th>\n",
       "      <th>OCC_989_ind</th>\n",
       "      <th>diagnosis_combo_frequency</th>\n",
       "      <th>sorted_diag_1</th>\n",
       "      <th>sorted_diag_2</th>\n",
       "      <th>sorted_diag_3</th>\n",
       "      <th>sorted_diag_1_frequency</th>\n",
       "      <th>sorted_diag_2_frequency</th>\n",
       "      <th>sorted_diag_3_frequency</th>\n",
       "      <th>diagnosis_combo_string</th>\n",
       "      <th>is_high_risk_combo</th>\n",
       "      <th>dx_428_ind_max</th>\n",
       "      <th>dx_428_ind_sum</th>\n",
       "      <th>dx_403_ind_max</th>\n",
       "      <th>dx_403_ind_sum</th>\n",
       "      <th>dx_707_ind_max</th>\n",
       "      <th>dx_707_ind_sum</th>\n",
       "      <th>dx_585_ind_max</th>\n",
       "      <th>dx_585_ind_sum</th>\n",
       "      <th>dx_491_ind_max</th>\n",
       "      <th>dx_491_ind_sum</th>\n",
       "      <th>dx_396_ind_max</th>\n",
       "      <th>dx_396_ind_sum</th>\n",
       "      <th>dx_440_ind_max</th>\n",
       "      <th>dx_440_ind_sum</th>\n",
       "      <th>dx_453_ind_max</th>\n",
       "      <th>dx_453_ind_sum</th>\n",
       "      <th>dx_571_ind_max</th>\n",
       "      <th>dx_571_ind_sum</th>\n",
       "      <th>dx_284_ind_max</th>\n",
       "      <th>dx_284_ind_sum</th>\n",
       "      <th>dx_304_ind_max</th>\n",
       "      <th>dx_304_ind_sum</th>\n",
       "      <th>dx_482_ind_max</th>\n",
       "      <th>dx_482_ind_sum</th>\n",
       "      <th>dx_150_ind_max</th>\n",
       "      <th>dx_150_ind_sum</th>\n",
       "      <th>dx_282_ind_max</th>\n",
       "      <th>dx_282_ind_sum</th>\n",
       "      <th>dx_332_ind_max</th>\n",
       "      <th>dx_332_ind_sum</th>\n",
       "      <th>dx_443_ind_max</th>\n",
       "      <th>dx_443_ind_sum</th>\n",
       "      <th>dx_719_ind_max</th>\n",
       "      <th>dx_719_ind_sum</th>\n",
       "      <th>dx_423_ind_max</th>\n",
       "      <th>dx_423_ind_sum</th>\n",
       "      <th>dx_281_ind_max</th>\n",
       "      <th>dx_281_ind_sum</th>\n",
       "      <th>dx_536_ind_max</th>\n",
       "      <th>dx_536_ind_sum</th>\n",
       "      <th>dx_368_ind_max</th>\n",
       "      <th>dx_368_ind_sum</th>\n",
       "      <th>dx_515_ind_max</th>\n",
       "      <th>dx_515_ind_sum</th>\n",
       "      <th>dx_595_ind_max</th>\n",
       "      <th>dx_595_ind_sum</th>\n",
       "      <th>dx_572_ind_max</th>\n",
       "      <th>dx_572_ind_sum</th>\n",
       "      <th>dx_681_ind_max</th>\n",
       "      <th>dx_681_ind_sum</th>\n",
       "      <th>dx_581_ind_max</th>\n",
       "      <th>dx_581_ind_sum</th>\n",
       "      <th>dx_537_ind_max</th>\n",
       "      <th>dx_537_ind_sum</th>\n",
       "      <th>dx_490_ind_max</th>\n",
       "      <th>dx_490_ind_sum</th>\n",
       "      <th>dx_583_ind_max</th>\n",
       "      <th>dx_583_ind_sum</th>\n",
       "      <th>dx_V46_ind_max</th>\n",
       "      <th>dx_V46_ind_sum</th>\n",
       "      <th>dx_519_ind_max</th>\n",
       "      <th>dx_519_ind_sum</th>\n",
       "      <th>dx_300_ind_max</th>\n",
       "      <th>dx_300_ind_sum</th>\n",
       "      <th>dx_567_ind_max</th>\n",
       "      <th>dx_567_ind_sum</th>\n",
       "      <th>dx_E92_ind_max</th>\n",
       "      <th>dx_E92_ind_sum</th>\n",
       "      <th>dx_V49_ind_max</th>\n",
       "      <th>dx_V49_ind_sum</th>\n",
       "      <th>dx_094_ind_max</th>\n",
       "      <th>dx_094_ind_sum</th>\n",
       "      <th>dx_514_ind_max</th>\n",
       "      <th>dx_514_ind_sum</th>\n",
       "      <th>dx_494_ind_max</th>\n",
       "      <th>dx_494_ind_sum</th>\n",
       "      <th>dx_042_ind_max</th>\n",
       "      <th>dx_042_ind_sum</th>\n",
       "      <th>dx_404_ind_max</th>\n",
       "      <th>dx_404_ind_sum</th>\n",
       "      <th>dx_346_ind_max</th>\n",
       "      <th>dx_346_ind_sum</th>\n",
       "      <th>dx_792_ind_max</th>\n",
       "      <th>dx_792_ind_sum</th>\n",
       "      <th>dx_398_ind_max</th>\n",
       "      <th>dx_398_ind_sum</th>\n",
       "      <th>dx_753_ind_max</th>\n",
       "      <th>dx_753_ind_sum</th>\n",
       "      <th>dx_577_ind_max</th>\n",
       "      <th>dx_577_ind_sum</th>\n",
       "      <th>dx_730_ind_max</th>\n",
       "      <th>dx_730_ind_sum</th>\n",
       "      <th>dx_444_ind_max</th>\n",
       "      <th>dx_444_ind_sum</th>\n",
       "      <th>dx_459_ind_max</th>\n",
       "      <th>dx_459_ind_sum</th>\n",
       "      <th>dx_790_ind_max</th>\n",
       "      <th>dx_790_ind_sum</th>\n",
       "      <th>dx_337_ind_max</th>\n",
       "      <th>dx_337_ind_sum</th>\n",
       "      <th>dx_397_ind_max</th>\n",
       "      <th>dx_397_ind_sum</th>\n",
       "      <th>dx_292_ind_max</th>\n",
       "      <th>dx_292_ind_sum</th>\n",
       "      <th>dx_V42_ind_max</th>\n",
       "      <th>dx_V42_ind_sum</th>\n",
       "      <th>dx_289_ind_max</th>\n",
       "      <th>dx_289_ind_sum</th>\n",
       "      <th>alcohol_history_ind</th>\n",
       "      <th>obesity_history_ind</th>\n",
       "      <th>mh_history_ind</th>\n",
       "      <th>encounter_ct</th>\n",
       "      <th>mb_time_in_hospital</th>\n",
       "      <th>mb_num_lab_procedures_ct</th>\n",
       "      <th>mb_num_procedures_ct</th>\n",
       "      <th>mb_num_medications_ct</th>\n",
       "      <th>mb_number_outpatient_ct</th>\n",
       "      <th>mb_number_emergency_ct</th>\n",
       "      <th>mb_number_inpatient_ct</th>\n",
       "      <th>mb_number_diagnoses_ct</th>\n",
       "      <th>age_encoded</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>250</td>\n",
       "      <td>V27</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DIABETES IN PREG-UNSPEC</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>DELIVER-SINGLE LIVEBORN</td>\n",
       "      <td>285</td>\n",
       "      <td>12794</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>DIABETES IN PREG-UNSPEC</td>\n",
       "      <td>DELIVER-SINGLE LIVEBORN</td>\n",
       "      <td>36015</td>\n",
       "      <td>417</td>\n",
       "      <td>37</td>\n",
       "      <td>(250 648 V27)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "      <td>403</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>INTEST INFEC E COLI NOS</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>MAL HY KID W CR KID I-IV</td>\n",
       "      <td>515</td>\n",
       "      <td>12794</td>\n",
       "      <td>2357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>MAL HY KID W CR KID I-IV</td>\n",
       "      <td>INTEST INFEC E COLI NOS</td>\n",
       "      <td>36015</td>\n",
       "      <td>2261</td>\n",
       "      <td>834</td>\n",
       "      <td>(250 403 8)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>157</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Emergency Room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SECONDARY MALIG NEO LUNG</td>\n",
       "      <td>MAL NEO PANCREAS HEAD</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>320</td>\n",
       "      <td>85</td>\n",
       "      <td>17157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>MAL NEO PANCREAS HEAD</td>\n",
       "      <td>SECONDARY MALIG NEO LUNG</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>233</td>\n",
       "      <td>608</td>\n",
       "      <td>189</td>\n",
       "      <td>(157 197 250)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35754</td>\n",
       "      <td>82637451</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>411</td>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Clinic Referral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>6581</td>\n",
       "      <td>2566</td>\n",
       "      <td>17157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>DIABETES MELLITUS</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>36015</td>\n",
       "      <td>1476</td>\n",
       "      <td>4041</td>\n",
       "      <td>(250 411 414)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55842</td>\n",
       "      <td>84259809</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>411</td>\n",
       "      <td>V45</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>Elective</td>\n",
       "      <td>Discharged to home</td>\n",
       "      <td>Clinic Referral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>STATUS CARDC DVCE UNSPCF</td>\n",
       "      <td>6581</td>\n",
       "      <td>2566</td>\n",
       "      <td>1389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>POST MI SYNDROME</td>\n",
       "      <td>COR ATH UNSP VSL NTV/GFT</td>\n",
       "      <td>STATUS CARDC DVCE UNSPCF</td>\n",
       "      <td>1650</td>\n",
       "      <td>5936</td>\n",
       "      <td>1698</td>\n",
       "      <td>(411 414 V45)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr  gender  time_in_hospital  num_lab_procedures  \\\n",
       "0         64410     86047875  Female                 2                  11   \n",
       "1        500364     82442376    Male                 2                  44   \n",
       "2         16680     42519267    Male                 1                  51   \n",
       "3         35754     82637451    Male                 3                  31   \n",
       "4         55842     84259809    Male                 4                  70   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "0               5               13                  2                 0   \n",
       "1               1               16                  0                 0   \n",
       "2               0                8                  0                 0   \n",
       "3               6               16                  0                 0   \n",
       "4               1               21                  0                 0   \n",
       "\n",
       "   number_inpatient diag_1 diag_2 diag_3  number_diagnoses A1Cresult  \\\n",
       "0                 1    648    250    V27                 6       NaN   \n",
       "1                 0      8    250    403                 7       NaN   \n",
       "2                 0    197    157    250                 5       NaN   \n",
       "3                 0    414    411    250                 9       NaN   \n",
       "4                 0    414    411    V45                 7       NaN   \n",
       "\n",
       "  metformin glimepiride glipizide glyburide pioglitazone rosiglitazone  \\\n",
       "0        No          No    Steady        No           No            No   \n",
       "1        No          No        No        No           No            No   \n",
       "2        No          No    Steady        No           No            No   \n",
       "3        No          No        No        No           No            No   \n",
       "4    Steady      Steady        No        No           No            No   \n",
       "\n",
       "  insulin change diabetesMed readmitted admission_type discharge_disposition  \\\n",
       "0      No     No         Yes         NO      Emergency    Discharged to home   \n",
       "1      Up     Ch         Yes         NO      Emergency    Discharged to home   \n",
       "2  Steady     Ch         Yes         NO      Emergency    Discharged to home   \n",
       "3  Steady     No         Yes        >30         Urgent    Discharged to home   \n",
       "4  Steady     Ch         Yes         NO       Elective    Discharged to home   \n",
       "\n",
       "  admission_source  mb_admission_grp_1_ct  mb_admission_grp_2_ct  \\\n",
       "0   Emergency Room                      1                      0   \n",
       "1   Emergency Room                      1                      0   \n",
       "2   Emergency Room                      1                      0   \n",
       "3  Clinic Referral                      0                      0   \n",
       "4  Clinic Referral                      0                      1   \n",
       "\n",
       "   mb_discharge_grp_1_ct  mb_discharge_grp_2_ct  mb_admission_type_ct  \\\n",
       "0                      1                      0                     0   \n",
       "1                      1                      0                     0   \n",
       "2                      1                      0                     0   \n",
       "3                      1                      0                     1   \n",
       "4                      1                      0                     1   \n",
       "\n",
       "   distinct_diag_count               diagnosis_1            diagnosis_2  \\\n",
       "0                    3   DIABETES IN PREG-UNSPEC      DIABETES MELLITUS   \n",
       "1                    3   INTEST INFEC E COLI NOS      DIABETES MELLITUS   \n",
       "2                    3  SECONDARY MALIG NEO LUNG  MAL NEO PANCREAS HEAD   \n",
       "3                    3  COR ATH UNSP VSL NTV/GFT       POST MI SYNDROME   \n",
       "4                    3  COR ATH UNSP VSL NTV/GFT       POST MI SYNDROME   \n",
       "\n",
       "                diagnosis_3  diag_1_freq  diag_2_freq  diag_3_freq  \\\n",
       "0   DELIVER-SINGLE LIVEBORN          285        12794           37   \n",
       "1  MAL HY KID W CR KID I-IV          515        12794         2357   \n",
       "2         DIABETES MELLITUS          320           85        17157   \n",
       "3         DIABETES MELLITUS         6581         2566        17157   \n",
       "4  STATUS CARDC DVCE UNSPCF         6581         2566         1389   \n",
       "\n",
       "   LTIS_38_ind  LTIS_40_ind  LTIS_36_ind  LTIS_320_ind  LTIS_324_ind  \\\n",
       "0            0            0            0             0             0   \n",
       "1            0            0            0             0             0   \n",
       "2            0            0            0             0             0   \n",
       "3            0            0            0             0             0   \n",
       "4            0            0            0             0             0   \n",
       "\n",
       "   CE_410_ind  CE_430_ind  CE_431_ind  CE_415_ind  CE_428_ind  CMN_155_ind  \\\n",
       "0           0           0           0           0           0            0   \n",
       "1           0           0           0           0           0            0   \n",
       "2           0           0           0           0           0            0   \n",
       "3           0           0           0           0           0            0   \n",
       "4           0           0           0           0           0            0   \n",
       "\n",
       "   CMN_162_ind  CMN_191_ind  CMN_197_ind  CMN_199_ind  OF_570_ind  OF_584_ind  \\\n",
       "0            0            0            0            0           0           0   \n",
       "1            0            0            0            0           0           0   \n",
       "2            0            0            0            0           0           0   \n",
       "3            0            0            0            0           0           0   \n",
       "4            0            0            0            0           0           0   \n",
       "\n",
       "   OF_585_ind  OF_277_ind  NBD_331_ind  NBD_340_ind  NBD_780_ind  NBD_852_ind  \\\n",
       "0           0           0            0            0            0            0   \n",
       "1           0           0            0            0            0            0   \n",
       "2           0           0            0            0            0            0   \n",
       "3           0           0            0            0            0            0   \n",
       "4           0           0            0            0            0            0   \n",
       "\n",
       "   STI_806_ind  STI_861_ind  STI_864_ind  STI_958_ind  OCC_250_ind  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            1   \n",
       "3            0            0            0            0            1   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   OCC_995_ind  OCC_986_ind  OCC_989_ind  diagnosis_combo_frequency  \\\n",
       "0            0            0            0                         15   \n",
       "1            0            0            0                          5   \n",
       "2            0            0            0                         14   \n",
       "3            0            0            0                        582   \n",
       "4            0            0            0                        104   \n",
       "\n",
       "           sorted_diag_1             sorted_diag_2             sorted_diag_3  \\\n",
       "0      DIABETES MELLITUS   DIABETES IN PREG-UNSPEC   DELIVER-SINGLE LIVEBORN   \n",
       "1      DIABETES MELLITUS  MAL HY KID W CR KID I-IV   INTEST INFEC E COLI NOS   \n",
       "2  MAL NEO PANCREAS HEAD  SECONDARY MALIG NEO LUNG         DIABETES MELLITUS   \n",
       "3      DIABETES MELLITUS          POST MI SYNDROME  COR ATH UNSP VSL NTV/GFT   \n",
       "4       POST MI SYNDROME  COR ATH UNSP VSL NTV/GFT  STATUS CARDC DVCE UNSPCF   \n",
       "\n",
       "   sorted_diag_1_frequency  sorted_diag_2_frequency  sorted_diag_3_frequency  \\\n",
       "0                    36015                      417                       37   \n",
       "1                    36015                     2261                      834   \n",
       "2                      233                      608                      189   \n",
       "3                    36015                     1476                     4041   \n",
       "4                     1650                     5936                     1698   \n",
       "\n",
       "  diagnosis_combo_string  is_high_risk_combo  dx_428_ind_max  dx_428_ind_sum  \\\n",
       "0          (250 648 V27)                   0               0               0   \n",
       "1            (250 403 8)                   0               0               0   \n",
       "2          (157 197 250)                   0               0               0   \n",
       "3          (250 411 414)                   0               0               0   \n",
       "4          (411 414 V45)                   0               0               0   \n",
       "\n",
       "   dx_403_ind_max  dx_403_ind_sum  dx_707_ind_max  dx_707_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               1               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_585_ind_max  dx_585_ind_sum  dx_491_ind_max  dx_491_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_396_ind_max  dx_396_ind_sum  dx_440_ind_max  dx_440_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_453_ind_max  dx_453_ind_sum  dx_571_ind_max  dx_571_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_284_ind_max  dx_284_ind_sum  dx_304_ind_max  dx_304_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_482_ind_max  dx_482_ind_sum  dx_150_ind_max  dx_150_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_282_ind_max  dx_282_ind_sum  dx_332_ind_max  dx_332_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_443_ind_max  dx_443_ind_sum  dx_719_ind_max  dx_719_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_423_ind_max  dx_423_ind_sum  dx_281_ind_max  dx_281_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_536_ind_max  dx_536_ind_sum  dx_368_ind_max  dx_368_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_515_ind_max  dx_515_ind_sum  dx_595_ind_max  dx_595_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_572_ind_max  dx_572_ind_sum  dx_681_ind_max  dx_681_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_581_ind_max  dx_581_ind_sum  dx_537_ind_max  dx_537_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_490_ind_max  dx_490_ind_sum  dx_583_ind_max  dx_583_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_V46_ind_max  dx_V46_ind_sum  dx_519_ind_max  dx_519_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_300_ind_max  dx_300_ind_sum  dx_567_ind_max  dx_567_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_E92_ind_max  dx_E92_ind_sum  dx_V49_ind_max  dx_V49_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_094_ind_max  dx_094_ind_sum  dx_514_ind_max  dx_514_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_494_ind_max  dx_494_ind_sum  dx_042_ind_max  dx_042_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_404_ind_max  dx_404_ind_sum  dx_346_ind_max  dx_346_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_792_ind_max  dx_792_ind_sum  dx_398_ind_max  dx_398_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_753_ind_max  dx_753_ind_sum  dx_577_ind_max  dx_577_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_730_ind_max  dx_730_ind_sum  dx_444_ind_max  dx_444_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_459_ind_max  dx_459_ind_sum  dx_790_ind_max  dx_790_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_337_ind_max  dx_337_ind_sum  dx_397_ind_max  dx_397_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_292_ind_max  dx_292_ind_sum  dx_V42_ind_max  dx_V42_ind_sum  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   dx_289_ind_max  dx_289_ind_sum  alcohol_history_ind  obesity_history_ind  \\\n",
       "0               0               0                    0                    0   \n",
       "1               0               0                    0                    0   \n",
       "2               0               0                    0                    0   \n",
       "3               0               0                    0                    0   \n",
       "4               0               0                    0                    0   \n",
       "\n",
       "   mh_history_ind  encounter_ct  mb_time_in_hospital  \\\n",
       "0               0             1                    2   \n",
       "1               0             1                    2   \n",
       "2               0             1                    1   \n",
       "3               0             1                    3   \n",
       "4               0             1                    4   \n",
       "\n",
       "   mb_num_lab_procedures_ct  mb_num_procedures_ct  mb_num_medications_ct  \\\n",
       "0                        11                     5                     13   \n",
       "1                        44                     1                     16   \n",
       "2                        51                     0                      8   \n",
       "3                        31                     6                     16   \n",
       "4                        70                     1                     21   \n",
       "\n",
       "   mb_number_outpatient_ct  mb_number_emergency_ct  mb_number_inpatient_ct  \\\n",
       "0                        2                       0                       1   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "\n",
       "   mb_number_diagnoses_ct  age_encoded  dummy  \n",
       "0                       6          1.0      1  \n",
       "1                       7          2.0      1  \n",
       "2                       5          3.0      1  \n",
       "3                       9          4.0      1  \n",
       "4                       7          5.0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "# The data was preprocessed in the data_preprocessing.ipynb notebook\n",
    "try:\n",
    "    data = pd.read_csv('../../dataPreprocessing/medical_data.csv')\n",
    "except FileNotFoundError:\n",
    "    data = pd.read_pickle('../../dataPreprocessing/medical_data.pkl')\n",
    "\n",
    "# These columns are derived from the target variable ('readmitted') and must be removed.\n",
    "leaky_features = ['mb_readmitted_lt30_ct', 'mb_readmitted_gt30_ct', 'mb_readmitted_no_ct', 'readmitted_ind']\n",
    "data.drop(columns=[col for col in leaky_features if col in data.columns], inplace=True, errors='ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Data head:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa19fb1",
   "metadata": {},
   "source": [
    "## Data Preparation and Preprocessing Strategy\n",
    "\n",
    "A critical prerequisite for building an effective deep learning model is a robust and well-defined data preprocessing pipeline. Our strategy is designed to handle the mixed data types present in the dataset (numerical, low-cardinality categorical, and high-cardinality categorical) and prepare them for their respective model branches.\n",
    "\n",
    "The process involves the following key steps:\n",
    "\n",
    "1.  **Feature and Target Definition**: We first define our target variable, `readmitted_binary`, and isolate the features that will be used for prediction.\n",
    "2.  **Feature Segregation**: We programmatically separate the features into three distinct groups based on their data type and cardinality (the number of unique values).\n",
    "3.  **Train-Test Split**: The data is split into training and testing sets *before* any transformations are fitted. This is a crucial step to prevent data leakage and ensure our final evaluation is unbiased.\n",
    "4.  **Unified Preprocessing Pipeline**: We use Scikit-learn's `ColumnTransformer` to apply the correct transformation to each feature group in a single, unified step:\n",
    "    *   **Numerical Features**: These are scaled using `StandardScaler` to normalize their range, which helps the model converge more efficiently.\n",
    "    *   **Low-Cardinality Categorical Features**: These are transformed using `OneHotEncoder`, creating a binary column for each category. This is suitable for features with a small number of unique values.\n",
    "    -   **High-Cardinality Categorical Features**: These are converted into unique integers using `OrdinalEncoder`. This is not for establishing order, but as a necessary step to prepare these features for the subsequent `Embedding` layers in our neural network, which will learn a meaningful vector representation for each integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594041a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable created.\n",
      "readmitted_binary\n",
      "0    42307\n",
      "1    35742\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The target variable is 'readmitted'. We'll convert this into a binary classification problem:\n",
    "# 1 if readmitted (value is '<30' or '>30'), 0 otherwise (value is 'NO').\n",
    "if 'readmitted' in data.columns:\n",
    "    data['readmitted_binary'] = data['readmitted'].apply(lambda x: 1 if x in ['<30', '>30'] else 0)\n",
    "    target = 'readmitted_binary'\n",
    "    \n",
    "    # Drop original readmitted columns and patient_nbr as it's an identifier\n",
    "    features = data.drop(columns=[target, 'readmitted', 'patient_nbr'], errors='ignore')\n",
    "    y = data[target]\n",
    "    X = features\n",
    "    \n",
    "    print(\"Target variable created.\")\n",
    "    print(y.value_counts())\n",
    "else:\n",
    "    print(\"Target column 'readmitted' not found. Please define the target variable.\")\n",
    "    # As a placeholder:\n",
    "    X, y = None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79acae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: 176\n",
      "Low-cardinality categorical features (to be one-hot encoded): 14\n",
      "High-cardinality categorical features (to be embedded): 10\n",
      " -> High-cardinality features: ['diag_1', 'diag_2', 'diag_3', 'diagnosis_1', 'diagnosis_2', 'diagnosis_3', 'sorted_diag_1', 'sorted_diag_2', 'sorted_diag_3', 'diagnosis_combo_string']\n",
      "\n",
      "Data split into training and testing sets.\n",
      "X_train shape: (62439, 200)\n",
      "X_test shape: (15610, 200)\n"
     ]
    }
   ],
   "source": [
    "if X is not None:\n",
    "    # Identify numerical and categorical features\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # Define a threshold for high cardinality\n",
    "    CARDINALITY_THRESHOLD = 50\n",
    "    \n",
    "    # Separate categorical features into low and high cardinality\n",
    "    high_cardinality_features = [col for col in categorical_features if X[col].nunique() > CARDINALITY_THRESHOLD]\n",
    "    low_cardinality_features = [col for col in categorical_features if X[col].nunique() <= CARDINALITY_THRESHOLD]\n",
    "\n",
    "    print(f\"Numerical features: {len(numerical_features)}\")\n",
    "    print(f\"Low-cardinality categorical features (to be one-hot encoded): {len(low_cardinality_features)}\")\n",
    "    print(f\"High-cardinality categorical features (to be embedded): {len(high_cardinality_features)}\")\n",
    "    print(f\" -> High-cardinality features: {high_cardinality_features}\")\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    print(\"\\nData split into training and testing sets.\")\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1082ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "Processed training data shape: (62439, 268)\n",
      "Processed testing data shape: (15610, 268)\n"
     ]
    }
   ],
   "source": [
    "if X is not None:\n",
    "    # Ensure all categorical columns are strings to avoid mixed-type errors\n",
    "    for col in low_cardinality_features + high_cardinality_features:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col] = X_train[col].astype(str)\n",
    "            X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "    # Create transformers for each feature type\n",
    "    numeric_transformer = StandardScaler()\n",
    "    low_card_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    high_card_transformer = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "    # Create a single preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_features),\n",
    "            ('cat_low', low_card_transformer, low_cardinality_features),\n",
    "            ('cat_high', high_card_transformer, high_cardinality_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Apply the preprocessing\n",
    "    # The preprocessor is FIT ONLY on the training data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    # It is then used to TRANSFORM both the training and test data\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n",
    "    print(\"Processed training data shape:\", X_train_processed.shape)\n",
    "    print(\"Processed testing data shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0896db5",
   "metadata": {},
   "source": [
    "## Model Architecture and Design\n",
    "\n",
    "To effectively handle the diverse types of data in our dataset, we have designed a hybrid neural network using the Keras Functional API. This flexible approach allows us to create a multi-branch model where different kinds of features are processed by specialized layers best suited for their nature. The outputs of these branches are then merged to make a final, unified prediction.\n",
    "\n",
    "The model consists of the following key components:\n",
    "\n",
    "### 1. Unified Input Layer\n",
    "A single `Input` layer serves as the entry point for the entire preprocessed feature vector. This vector contains the scaled numerical features, the one-hot encoded low-cardinality features, and the integer-encoded high-cardinality features, all concatenated together.\n",
    "\n",
    "### 2. Branch 1: CNN for Numerical and Low-Cardinality Features\n",
    "This branch is designed to process the continuous numerical data and the one-hot encoded categorical data. It uses a 1D Convolutional Neural Network (CNN) to learn spatial hierarchies and patterns within this feature set.\n",
    "*   **Slicing (`Lambda`):** A `Lambda` layer first slices the main input tensor to isolate only the numerical and one-hot encoded columns.\n",
    "*   **Reshaping:** The sliced data is reshaped into a 3D tensor, which is the required input format for a `Conv1D` layer.\n",
    "*   **Convolution (`Conv1D`):** A 1D convolutional layer with a `relu` activation scans the features to identify local patterns.\n",
    "*   **Pooling (`MaxPooling1D`):** A max-pooling layer downsamples the output, making the learned patterns more robust.\n",
    "*   **Flattening:** The pooled feature map is flattened into a 1D vector to be passed to the final classification layers.\n",
    "\n",
    "### 3. Branch 2: Embeddings for High-Cardinality Features\n",
    "This branch is dedicated to handling the high-cardinality categorical features, which are not suitable for one-hot encoding.\n",
    "*   **Slicing (`Lambda`):** For each high-cardinality feature, a `Lambda` layer slices the main input tensor to extract its specific integer-encoded value.\n",
    "*   **Embedding (`Embedding`):** An `Embedding` layer converts each integer into a dense, low-dimensional vector. This layer learns a meaningful representation for each category, capturing semantic relationships between them.\n",
    "*   **Flattening:** The resulting embedding vectors are flattened to prepare them for merging.\n",
    "\n",
    "### 4. Merging and Final Classification\n",
    "*   **Concatenation:** The output vector from the CNN branch is concatenated with the output vectors from all the embedding branches, creating a single, comprehensive feature vector.\n",
    "*   **Classification Head:** This final, fully-connected part of the network makes the prediction:\n",
    "    *   One or two `Dense` layers with `relu` activation functions learn complex, non-linear combinations of the merged features.\n",
    "    *   A `Dropout` layer is applied for regularization to prevent overfitting.\n",
    "    *   The final `Dense` output layer consists of a single neuron with a `sigmoid` activation function, which outputs a probability score between 0 and 1 for the binary classification task (readmitted or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb75cc",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna\n",
    "\n",
    "To find the optimal configuration for our model, we employ a systematic hyperparameter tuning process using the Optuna framework. This process is divided into two key functions:\n",
    "\n",
    "1.  **`build_model(params)`**: This is a centralized factory function that constructs and compiles our hybrid CNN-Embedding model. It accepts a `params` dictionary, allowing us to dynamically create different versions of the model architecture based on the hyperparameters suggested by Optuna.\n",
    "\n",
    "2.  **`objective(trial)`**: This is the core function that Optuna interacts with. For each trial, it performs the following steps:\n",
    "    *   **Defines the Search Space**: It asks Optuna to suggest a new set of hyperparameters. This includes the learning rate, CNN filter count and kernel size, embedding dimension, dropout rate, batch size, and the number and size of the final dense layers.\n",
    "    *   **Builds the Model**: It passes the suggested hyperparameters to our `build_model` function.\n",
    "    *   **Trains and Validates**: It trains the model on a portion of the training data, using a `validation_split` and an `EarlyStopping` callback. This is crucial for getting an unbiased performance estimate and preventing overfitting within each trial.\n",
    "    *   **Stores Results**: The training history is saved to the trial's user attributes for later analysis.\n",
    "    *   **Returns the Score**: It returns the best validation loss achieved during the trial, which Optuna then uses to guide its search for the next trial.\n",
    "\n",
    "The `study.optimize()` command executes this process for a set number of trials, intelligently exploring the hyperparameter space to find the combination that minimizes validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b7a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):    \n",
    "    # --- 1. Get data shape information from the preprocessor ---\n",
    "    num_ohe_features = preprocessor.named_transformers_['cat_low'].get_feature_names_out().shape[0]\n",
    "    ohe_start_idx = len(numerical_features)\n",
    "    embed_start_idx = ohe_start_idx + num_ohe_features\n",
    "    \n",
    "    input_layer = Input(shape=(X_train_processed.shape[1],), name='main_input')\n",
    "\n",
    "    # --- 2. CNN Branch for numerical and one-hot encoded features ---\n",
    "    cnn_input_data = Lambda(lambda x: x[:, :embed_start_idx])(input_layer)\n",
    "    reshaped_cnn_data = Reshape((embed_start_idx, 1))(cnn_input_data)\n",
    "    conv1d = Conv1D(filters=params['cnn_filters'], kernel_size=params['kernel_size'], activation='relu')(reshaped_cnn_data)\n",
    "    pool1d = MaxPooling1D(pool_size=2)(conv1d)\n",
    "    flatten_cnn = Flatten()(pool1d)\n",
    "\n",
    "    # --- 3. Embedding Branch for high-cardinality features ---\n",
    "    embedding_layers = []\n",
    "    for i, col_name in enumerate(high_cardinality_features):\n",
    "        category_input = Lambda(lambda x: x[:, embed_start_idx + i])(input_layer)\n",
    "        vocab_size = len(preprocessor.named_transformers_['cat_high'].categories_[i])\n",
    "        embedding = Embedding(input_dim=vocab_size, output_dim=params['embedding_dim'])(category_input)\n",
    "        flatten_embed = Flatten()(embedding)\n",
    "        embedding_layers.append(flatten_embed)\n",
    "\n",
    "    # --- 4. Merge branches and add final classification layers ---\n",
    "    merged = concatenate([flatten_cnn] + embedding_layers)\n",
    "    \n",
    "    # Use a loop to create a variable number of dense layers\n",
    "    x = merged\n",
    "    for i in range(params['n_dense_layers']):\n",
    "        x = Dense(units=params[f'dense_units_{i+1}'], activation='relu')(x)\n",
    "        \n",
    "    dropout1 = Dropout(rate=params['dropout_rate'])(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dropout1)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    # --- 5. Compile the model ---\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=params['learning_rate']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27ea29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-30 21:46:24,841] A new study created in memory with name: no-name-3e1c0de3-92f2-44ac-a813-ce7235659655\n",
      "I0000 00:00:1751334385.051671     854 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751334389.225999    1119 service.cc:152] XLA service 0x7bdc4c002220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751334389.226046    1119 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-06-30 21:46:29.312288: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751334389.698333    1119 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-06-30 21:46:30.330057: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:30.396720: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:30.659428: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1751334392.681113    1119 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[I 2025-06-30 21:46:51,549] Trial 0 finished with value: 0.45772773027420044 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00852379628270222, 'cnn_filters': 32, 'kernel_size': 3, 'embedding_dim': 18, 'dropout_rate': 0.4792487333278708, 'batch_size': 64, 'dense_units_1': 128, 'dense_units_2': 32}. Best is trial 0 with value: 0.45772773027420044.\n",
      "2025-06-30 21:46:55.351273: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:55.523398: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:55.734876: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:56.149901: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 280 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:56.195609: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:56.274707: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829_0', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-30 21:46:56.556401: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2025-06-30 21:47:00.418889: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-30 21:47:00.582964: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-06-30 21:47:03.487533: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-30 21:47:03.627586: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2025-06-30 21:47:03.728823: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 164 bytes spill stores, 172 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 21:47:13,781] Trial 1 finished with value: 0.43930763006210327 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0015305695843967427, 'cnn_filters': 64, 'kernel_size': 3, 'embedding_dim': 15, 'dropout_rate': 0.533840167997619, 'batch_size': 256, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 1 with value: 0.43930763006210327.\n",
      "[I 2025-06-30 21:47:44,487] Trial 2 finished with value: 0.4535488188266754 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.004064943972759025, 'cnn_filters': 32, 'kernel_size': 5, 'embedding_dim': 14, 'dropout_rate': 0.27893986051878944, 'batch_size': 64, 'dense_units_1': 256}. Best is trial 1 with value: 0.43930763006210327.\n",
      "2025-06-30 21:47:48.349690: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 21:48:27,864] Trial 3 finished with value: 0.4539662003517151 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.006421401260363603, 'cnn_filters': 128, 'kernel_size': 7, 'embedding_dim': 26, 'dropout_rate': 0.4794818397352357, 'batch_size': 64, 'dense_units_1': 64, 'dense_units_2': 32}. Best is trial 1 with value: 0.43930763006210327.\n",
      "2025-06-30 21:48:31.176881: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-30 21:48:31.548406: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-30 21:48:31.818212: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2025-06-30 21:48:31.864181: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2025-06-30 21:48:32.207347: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 156 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2025-06-30 21:48:38.159441: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-30 21:48:38.373281: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2025-06-30 21:48:38.459329: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 164 bytes spill stores, 172 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 21:49:00,473] Trial 4 finished with value: 0.43912768363952637 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0004868021893715704, 'cnn_filters': 32, 'kernel_size': 3, 'embedding_dim': 19, 'dropout_rate': 0.44977107659549265, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 4 with value: 0.43912768363952637.\n",
      "[I 2025-06-30 21:50:05,097] Trial 5 finished with value: 0.4402904212474823 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.0022572824679782926, 'cnn_filters': 32, 'kernel_size': 3, 'embedding_dim': 30, 'dropout_rate': 0.5693913147767917, 'batch_size': 64, 'dense_units_1': 64}. Best is trial 4 with value: 0.43912768363952637.\n",
      "[I 2025-06-30 21:50:30,624] Trial 6 finished with value: 0.45034730434417725 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.0022000238420089168, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 24, 'dropout_rate': 0.22830709827186643, 'batch_size': 64, 'dense_units_1': 128}. Best is trial 4 with value: 0.43912768363952637.\n",
      "[I 2025-06-30 21:51:11,311] Trial 7 finished with value: 0.44044607877731323 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.001628654508448942, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 18, 'dropout_rate': 0.3817755250903626, 'batch_size': 128, 'dense_units_1': 128}. Best is trial 4 with value: 0.43912768363952637.\n",
      "[I 2025-06-30 21:51:48,759] Trial 8 finished with value: 0.43703025579452515 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00026017903690950993, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 8, 'dropout_rate': 0.2669021203805134, 'batch_size': 128, 'dense_units_1': 256}. Best is trial 8 with value: 0.43703025579452515.\n",
      "[I 2025-06-30 21:53:08,914] Trial 9 finished with value: 0.4359971582889557 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00023066123870989574, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 16, 'dropout_rate': 0.4498641641380187, 'batch_size': 64, 'dense_units_1': 256}. Best is trial 9 with value: 0.4359971582889557.\n",
      "[I 2025-06-30 21:53:48,251] Trial 10 finished with value: 0.436454713344574 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00010586632190867283, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 8, 'dropout_rate': 0.36700652110477516, 'batch_size': 256, 'dense_units_1': 256}. Best is trial 9 with value: 0.4359971582889557.\n",
      "[I 2025-06-30 21:54:29,854] Trial 11 finished with value: 0.43586453795433044 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00010402208349100441, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 8, 'dropout_rate': 0.36359903262845894, 'batch_size': 256, 'dense_units_1': 256}. Best is trial 11 with value: 0.43586453795433044.\n",
      "[I 2025-06-30 21:55:04,165] Trial 12 finished with value: 0.4368501901626587 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.0001024750390516314, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 12, 'dropout_rate': 0.33084549385599843, 'batch_size': 256, 'dense_units_1': 256}. Best is trial 11 with value: 0.43586453795433044.\n",
      "[I 2025-06-30 21:55:40,705] Trial 13 finished with value: 0.4359290897846222 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00024243009889198986, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 11, 'dropout_rate': 0.413544373571923, 'batch_size': 256, 'dense_units_1': 256}. Best is trial 11 with value: 0.43586453795433044.\n",
      "[I 2025-06-30 21:56:06,322] Trial 14 finished with value: 0.4399048089981079 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.000522298060707705, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 11, 'dropout_rate': 0.32311747475253644, 'batch_size': 256, 'dense_units_1': 256}. Best is trial 11 with value: 0.43586453795433044.\n",
      "[I 2025-06-30 21:56:36,755] Trial 15 finished with value: 0.43777740001678467 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.0002195995924169672, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 11, 'dropout_rate': 0.41456492778379156, 'batch_size': 256, 'dense_units_1': 256}. Best is trial 11 with value: 0.43586453795433044.\n",
      "[I 2025-06-30 21:56:55,822] Trial 16 finished with value: 0.4414930045604706 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.0006049757616057328, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 22, 'dropout_rate': 0.3252114151742066, 'batch_size': 256, 'dense_units_1': 256}. Best is trial 11 with value: 0.43586453795433044.\n",
      "[I 2025-06-30 21:57:26,037] Trial 17 finished with value: 0.4366784393787384 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00016754835521768936, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 9, 'dropout_rate': 0.39676433006921763, 'batch_size': 256, 'dense_units_1': 64}. Best is trial 11 with value: 0.43586453795433044.\n",
      "2025-06-30 21:57:30.138342: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:30.695990: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:30.706984: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:30.915323: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864_0', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:30.999337: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864_0', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:31.147769: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:31.153675: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 280 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:31.320593: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829_0', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:31.464342: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829_0', 472 bytes spill stores, 472 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:35.425813: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:35.520489: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:38.501524: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:38.510979: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:38.563325: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205_0', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "2025-06-30 21:57:38.646878: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205_0', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 21:57:52,574] Trial 18 finished with value: 0.435131698846817 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00030568907089672154, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 13, 'dropout_rate': 0.512983781503393, 'batch_size': 256, 'dense_units_1': 256, 'dense_units_2': 128}. Best is trial 18 with value: 0.435131698846817.\n",
      "[I 2025-06-30 21:58:13,606] Trial 19 finished with value: 0.4389898180961609 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0007132668879200542, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 14, 'dropout_rate': 0.5415382652536143, 'batch_size': 256, 'dense_units_1': 256, 'dense_units_2': 128}. Best is trial 18 with value: 0.435131698846817.\n",
      "2025-06-30 21:58:18.743806: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2025-06-30 21:58:18.896757: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 504 bytes spill stores, 504 bytes spill loads\n",
      "\n",
      "2025-06-30 21:58:18.953777: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 280 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2025-06-30 21:58:19.019548: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n",
      "2025-06-30 21:58:26.298201: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2025-06-30 21:58:26.354172: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 280 bytes spill stores, 284 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 21:58:39,459] Trial 20 finished with value: 0.43402284383773804 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0003812620070819225, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 31, 'dropout_rate': 0.5895348418255474, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 20 with value: 0.43402284383773804.\n",
      "[I 2025-06-30 21:59:02,282] Trial 21 finished with value: 0.43542635440826416 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0003762667348234867, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 29, 'dropout_rate': 0.5613775193313939, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 20 with value: 0.43402284383773804.\n",
      "[I 2025-06-30 21:59:22,247] Trial 22 finished with value: 0.4376731812953949 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00037771304050359235, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 31, 'dropout_rate': 0.5991888001025548, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 20 with value: 0.43402284383773804.\n",
      "[I 2025-06-30 21:59:47,073] Trial 23 finished with value: 0.43651682138442993 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0003709661240356755, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 28, 'dropout_rate': 0.5221515252443614, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 20 with value: 0.43402284383773804.\n",
      "[I 2025-06-30 22:00:06,150] Trial 24 finished with value: 0.4431949257850647 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.000904714003305678, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 28, 'dropout_rate': 0.5986277361890814, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 20 with value: 0.43402284383773804.\n",
      "2025-06-30 22:00:10.302631: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n",
      "2025-06-30 22:00:10.489508: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2025-06-30 22:00:17.091238: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 22:00:34,385] Trial 25 finished with value: 0.43614858388900757 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00034333904864132134, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 22, 'dropout_rate': 0.5624596089636144, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 20 with value: 0.43402284383773804.\n",
      "[I 2025-06-30 22:01:03,521] Trial 26 finished with value: 0.4327167272567749 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0001465034286196501, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 32, 'dropout_rate': 0.5078098660933741, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 26 with value: 0.4327167272567749.\n",
      "[I 2025-06-30 22:01:31,027] Trial 27 finished with value: 0.4351044297218323 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00015818889358730192, 'cnn_filters': 64, 'kernel_size': 7, 'embedding_dim': 32, 'dropout_rate': 0.5034927289655778, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 26 with value: 0.4327167272567749.\n",
      "[I 2025-06-30 22:02:06,324] Trial 28 finished with value: 0.4316125810146332 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00015896383475718525, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 32, 'dropout_rate': 0.4991303866725494, 'batch_size': 256, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 28 with value: 0.4316125810146332.\n",
      "[I 2025-06-30 22:02:41,464] Trial 29 finished with value: 0.43333521485328674 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00015421969892587538, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 32, 'dropout_rate': 0.46988199121163593, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 28 with value: 0.4316125810146332.\n",
      "[I 2025-06-30 22:03:18,244] Trial 30 finished with value: 0.4327804744243622 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00015638633950292908, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 27, 'dropout_rate': 0.47092305317169925, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 28 with value: 0.4316125810146332.\n",
      "[I 2025-06-30 22:03:52,661] Trial 31 finished with value: 0.43130841851234436 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00015986739925181708, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 26, 'dropout_rate': 0.4745216494438844, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 31 with value: 0.43130841851234436.\n",
      "[I 2025-06-30 22:04:29,587] Trial 32 finished with value: 0.4302065670490265 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00014449566556250527, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 25, 'dropout_rate': 0.4834147059818392, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 32 with value: 0.4302065670490265.\n",
      "[I 2025-06-30 22:05:06,225] Trial 33 finished with value: 0.4318018853664398 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00017959375933628168, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 25, 'dropout_rate': 0.495822624998339, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 128}. Best is trial 32 with value: 0.4302065670490265.\n",
      "2025-06-30 22:05:11.285364: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 22:05:55,836] Trial 34 finished with value: 0.4317761957645416 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00019213391447353039, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 24, 'dropout_rate': 0.4432522101739428, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 32 with value: 0.4302065670490265.\n",
      "[I 2025-06-30 22:06:40,114] Trial 35 finished with value: 0.4291423559188843 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00012181110533189394, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 23, 'dropout_rate': 0.434872634551453, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:07:24,091] Trial 36 finished with value: 0.43051162362098694 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00012718826256913674, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 21, 'dropout_rate': 0.43293912307397403, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:08:06,481] Trial 37 finished with value: 0.43097028136253357 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00012420431053719987, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 21, 'dropout_rate': 0.4391772296403117, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:08:54,120] Trial 38 finished with value: 0.4325852692127228 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0001226650588117843, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 21, 'dropout_rate': 0.4296334665490178, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:09:16,036] Trial 39 finished with value: 0.45512834191322327 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.004458859811426195, 'cnn_filters': 32, 'kernel_size': 3, 'embedding_dim': 18, 'dropout_rate': 0.4324889087352423, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:09:38,790] Trial 40 finished with value: 0.4522084593772888 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.008011758351354968, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 20, 'dropout_rate': 0.3926841293617297, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:10:16,315] Trial 41 finished with value: 0.43168002367019653 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00012781197703957948, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 23, 'dropout_rate': 0.4568488292164659, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:10:59,121] Trial 42 finished with value: 0.4310687780380249 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0001253906209654012, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 26, 'dropout_rate': 0.47864130801602683, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:11:41,030] Trial 43 finished with value: 0.4307515621185303 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00012630299057675304, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 20, 'dropout_rate': 0.48756358313921067, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:12:16,218] Trial 44 finished with value: 0.4322204887866974 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0002692082362131916, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 17, 'dropout_rate': 0.4190493671299765, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:13:28,250] Trial 45 finished with value: 0.43289580941200256 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00010196073331237088, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 19, 'dropout_rate': 0.4585830079736073, 'batch_size': 64, 'dense_units_1': 128, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:14:02,036] Trial 46 finished with value: 0.43588653206825256 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00020101524456023385, 'cnn_filters': 32, 'kernel_size': 3, 'embedding_dim': 20, 'dropout_rate': 0.3709555291769988, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:14:19,565] Trial 47 finished with value: 0.44973576068878174 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0014748847658221688, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 23, 'dropout_rate': 0.34771131419430196, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:14:59,364] Trial 48 finished with value: 0.43244069814682007 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00013060225490941956, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 21, 'dropout_rate': 0.4883448932699918, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:15:52,840] Trial 49 finished with value: 0.43482524156570435 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0002197719603515624, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 24, 'dropout_rate': 0.5316495511945156, 'batch_size': 64, 'dense_units_1': 128, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:16:30,127] Trial 50 finished with value: 0.4388526678085327 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0002876164078880498, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 16, 'dropout_rate': 0.21236103310745888, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:17:12,974] Trial 51 finished with value: 0.4302988648414612 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00012181336329001032, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 26, 'dropout_rate': 0.4346931176912398, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:17:54,922] Trial 52 finished with value: 0.4300854206085205 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00011638775719647645, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 22, 'dropout_rate': 0.4379170954922058, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:18:33,354] Trial 53 finished with value: 0.43028101325035095 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00011012842491325644, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 25, 'dropout_rate': 0.4208638711678742, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:19:17,310] Trial 54 finished with value: 0.43536466360092163 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0001140328414184828, 'cnn_filters': 32, 'kernel_size': 3, 'embedding_dim': 25, 'dropout_rate': 0.41542648206033905, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:19:56,051] Trial 55 finished with value: 0.434141606092453 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00019994492642019554, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 23, 'dropout_rate': 0.38911796946922317, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:20:42,325] Trial 56 finished with value: 0.43000972270965576 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00010655438736562475, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 25, 'dropout_rate': 0.40126757295993487, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "2025-06-30 22:20:46.179251: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_864', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-30 22:20:52.788951: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 144 bytes spill stores, 144 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 22:21:26,008] Trial 57 finished with value: 0.4320886731147766 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00010010705047492488, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 27, 'dropout_rate': 0.4067417500508989, 'batch_size': 128, 'dense_units_1': 128, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:22:09,454] Trial 58 finished with value: 0.4346699118614197 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00024180402916918695, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 25, 'dropout_rate': 0.3796089598617773, 'batch_size': 64, 'dense_units_1': 64, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:23:09,695] Trial 59 finished with value: 0.4330568015575409 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00010036808102038167, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 26, 'dropout_rate': 0.30130428847329366, 'batch_size': 128, 'dense_units_1': 128}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:23:52,285] Trial 60 finished with value: 0.43633872270584106 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00013508776389350768, 'cnn_filters': 32, 'kernel_size': 3, 'embedding_dim': 29, 'dropout_rate': 0.45572340275421397, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:24:29,641] Trial 61 finished with value: 0.43355390429496765 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0001419690948759176, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 22, 'dropout_rate': 0.4225155488984586, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:25:09,900] Trial 62 finished with value: 0.43256816267967224 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00018209788582948367, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 23, 'dropout_rate': 0.4006076417248745, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:25:57,317] Trial 63 finished with value: 0.42993366718292236 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00011451845415957916, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 24, 'dropout_rate': 0.44313718855326467, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:26:38,630] Trial 64 finished with value: 0.4302603602409363 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00011378723609380381, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 27, 'dropout_rate': 0.4519599772347368, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:26:58,325] Trial 65 finished with value: 0.4479067623615265 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0026345606215841724, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 27, 'dropout_rate': 0.3557712907156122, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:27:47,481] Trial 66 finished with value: 0.4323265552520752 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00011133181055235993, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 25, 'dropout_rate': 0.4626081417899214, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 32}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:28:35,761] Trial 67 finished with value: 0.43280497193336487 and parameters: {'n_dense_layers': 1, 'learning_rate': 0.00017525371263339877, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 28, 'dropout_rate': 0.4467624016070334, 'batch_size': 128, 'dense_units_1': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "2025-06-30 22:28:47.078868: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "[I 2025-06-30 22:29:05,519] Trial 68 finished with value: 0.4396255314350128 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0004420409498432564, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 24, 'dropout_rate': 0.40553799556005216, 'batch_size': 64, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:29:48,715] Trial 69 finished with value: 0.43195515871047974 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00014252952751695182, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 24, 'dropout_rate': 0.3793395735966429, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 35 with value: 0.4291423559188843.\n",
      "[I 2025-06-30 22:30:32,021] Trial 70 finished with value: 0.42897289991378784 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00011299244102781563, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 22, 'dropout_rate': 0.45172970657173284, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 70 with value: 0.42897289991378784.\n",
      "[I 2025-06-30 22:31:06,476] Trial 71 finished with value: 0.4300978481769562 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00014715821422743054, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 22, 'dropout_rate': 0.44789169835893367, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 70 with value: 0.42897289991378784.\n",
      "[I 2025-06-30 22:31:47,578] Trial 72 finished with value: 0.4285860061645508 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00014815178232990324, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 22, 'dropout_rate': 0.44764889494154536, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 72 with value: 0.4285860061645508.\n",
      "[I 2025-06-30 22:32:30,620] Trial 73 finished with value: 0.4335760474205017 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.00017169832848592113, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 22, 'dropout_rate': 0.46853808432517374, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 72 with value: 0.4285860061645508.\n",
      "[I 2025-06-30 22:33:07,807] Trial 74 finished with value: 0.4318448007106781 and parameters: {'n_dense_layers': 2, 'learning_rate': 0.0002141325203887387, 'cnn_filters': 128, 'kernel_size': 5, 'embedding_dim': 22, 'dropout_rate': 0.4832806520558719, 'batch_size': 128, 'dense_units_1': 64, 'dense_units_2': 64}. Best is trial 72 with value: 0.4285860061645508.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (val_loss): 0.4285860061645508\n",
      "  Params: \n",
      "    n_dense_layers: 2\n",
      "    learning_rate: 0.00014815178232990324\n",
      "    cnn_filters: 128\n",
      "    kernel_size: 5\n",
      "    embedding_dim: 22\n",
      "    dropout_rate: 0.44764889494154536\n",
      "    batch_size: 128\n",
      "    dense_units_1: 64\n",
      "    dense_units_2: 64\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "     # --- 1. Define Expanded Hyperparameter Search Space ---\n",
    "    n_dense_layers = trial.suggest_categorical('n_dense_layers', [1, 2])\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "        'cnn_filters': trial.suggest_categorical('cnn_filters', [32, 64, 128]),\n",
    "        'kernel_size': trial.suggest_categorical('kernel_size', [3, 5, 7]), # New\n",
    "        'embedding_dim': trial.suggest_int('embedding_dim', 8, 32),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.2, 0.6), # Slightly adjusted range\n",
    "        'n_dense_layers': n_dense_layers, # New\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256]) # New\n",
    "    }\n",
    "     \n",
    "     # Define layer units based on the number of layers\n",
    "    params['dense_units_1'] = trial.suggest_categorical('dense_units_1', [64, 128, 256])\n",
    "    if n_dense_layers == 2:\n",
    "        params['dense_units_2'] = trial.suggest_categorical('dense_units_2', [32, 64, 128])\n",
    "\n",
    "\n",
    "    # --- 2. Build and compile the model ---\n",
    "    model = build_model(params)\n",
    "    \n",
    "    # --- 3. Train the Model ---\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        X_train_processed, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    # --- 4. Evaluate and Return the Metric to Optimize ---\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    # Store the history in the trial to access it later\n",
    "    trial.set_user_attr(\"history\", history.history) \n",
    "    return val_loss\n",
    "\n",
    "# --- Run the Optuna Study ---\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=75) # Run 75 trials to find the best hyperparameters\n",
    "\n",
    "# --- Print the Best Results ---\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"  Value (val_loss): {best_trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e06d9",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Final Model\n",
    "\n",
    "After the Optuna study has identified the most promising set of hyperparameters, the final step is to train a definitive model and evaluate its performance on the unseen test set. This process ensures we are using our data and the insights from tuning as effectively as possible.\n",
    "\n",
    "The workflow is as follows:\n",
    "\n",
    "1.  **Retrieve Best Hyperparameters**: We extract the `best_params` dictionary from the completed Optuna study. These are the parameters that yielded the lowest validation loss.\n",
    "\n",
    "2.  **Determine Optimal Training Duration**: To prevent overfitting, we do not train for a fixed number of epochs. Instead, we inspect the saved `history` from the best trial and find the exact epoch (`optimal_epochs`) at which the validation loss was at its minimum. This is the ideal training duration for our specific model architecture and data.\n",
    "\n",
    "3.  **Build and Train the Final Model**: We call the `build_model` function one last time using the `best_params`. Then, we train this model on the **entire training dataset** for the `optimal_epochs` we just determined. No validation set is used here, as all model-selection decisions have already been made. This step ensures the final model learns from all available training data.\n",
    "\n",
    "4.  **Final Evaluation**: The fully trained model is evaluated against the completely separate test set. The resulting test accuracy, loss, and AUC score provide the most reliable measure of how the model is expected to perform on new, real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d3a896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_75\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_75\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ main_input          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">268</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_825 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ reshape_75          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ lambda_825[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> ‚îÇ reshape_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_826 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_827 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_828 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_829 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_830 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_831 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_832 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_833 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_834 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_835 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ main_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling1d_75    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ conv1d_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_750       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,322</span> ‚îÇ lambda_826[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_751       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,838</span> ‚îÇ lambda_827[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_752       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,322</span> ‚îÇ lambda_828[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_753       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,322</span> ‚îÇ lambda_829[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_754       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,838</span> ‚îÇ lambda_830[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_755       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,322</span> ‚îÇ lambda_831[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_756       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,484</span> ‚îÇ lambda_832[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_757       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,750</span> ‚îÇ lambda_833[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_758       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,552</span> ‚îÇ lambda_834[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_759       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">606,892</span> ‚îÇ lambda_835[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_825         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16256</span>)     ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ max_pooling1d_75‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_826         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_750[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_827         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_751[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_828         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_752[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_829         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_753[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_830         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_754[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_831         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_755[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_832         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_756[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_833         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_757[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_834         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_758[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_835         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ embedding_759[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ concatenate_75      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16476</span>)     ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ flatten_825[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       ‚îÇ                   ‚îÇ            ‚îÇ flatten_826[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_827[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_828[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_829[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_830[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_831[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_832[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_833[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_834[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_835[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_209 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        ‚îÇ  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,054,528</span> ‚îÇ concatenate_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>‚Ä¶ ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_210 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> ‚îÇ dense_209[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_75          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense_210[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_211 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> ‚îÇ dropout_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ main_input          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m268\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_825 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ reshape_75          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m, \u001b[38;5;34m1\u001b[0m)    ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ lambda_825[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mReshape\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv1d_75 (\u001b[38;5;33mConv1D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m128\u001b[0m)  ‚îÇ        \u001b[38;5;34m768\u001b[0m ‚îÇ reshape_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_826 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_827 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_828 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_829 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_830 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_831 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_832 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_833 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_834 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lambda_835 (\u001b[38;5;33mLambda\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m)            ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ main_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling1d_75    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m128\u001b[0m)  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ conv1d_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_750       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m14,322\u001b[0m ‚îÇ lambda_826[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_751       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m13,838\u001b[0m ‚îÇ lambda_827[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_752       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m14,322\u001b[0m ‚îÇ lambda_828[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_753       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m14,322\u001b[0m ‚îÇ lambda_829[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_754       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m13,838\u001b[0m ‚îÇ lambda_830[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_755       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m14,322\u001b[0m ‚îÇ lambda_831[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_756       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m11,484\u001b[0m ‚îÇ lambda_832[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_757       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m13,750\u001b[0m ‚îÇ lambda_833[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_758       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ     \u001b[38;5;34m13,552\u001b[0m ‚îÇ lambda_834[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ embedding_759       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ    \u001b[38;5;34m606,892\u001b[0m ‚îÇ lambda_835[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_825         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16256\u001b[0m)     ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ max_pooling1d_75‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_826         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_750[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_827         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_751[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_828         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_752[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_829         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_753[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_830         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_754[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_831         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_755[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_832         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_756[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_833         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_757[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_834         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_758[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ flatten_835         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ embedding_759[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mFlatten\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ concatenate_75      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16476\u001b[0m)     ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ flatten_825[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mConcatenate\u001b[0m)       ‚îÇ                   ‚îÇ            ‚îÇ flatten_826[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_827[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_828[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_829[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_830[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_831[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_832[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_833[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_834[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ                   ‚îÇ            ‚îÇ flatten_835[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_209 (\u001b[38;5;33mDense\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ  \u001b[38;5;34m1,054,528\u001b[0m ‚îÇ concatenate_75[\u001b[38;5;34m0\u001b[0m‚Ä¶ ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_210 (\u001b[38;5;33mDense\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ      \u001b[38;5;34m4,160\u001b[0m ‚îÇ dense_209[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_75          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense_210[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mDropout\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_211 (\u001b[38;5;33mDense\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         ‚îÇ         \u001b[38;5;34m65\u001b[0m ‚îÇ dropout_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,790,163</span> (6.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,790,163\u001b[0m (6.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,790,163</span> (6.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,790,163\u001b[0m (6.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal number of epochs found: 14\n",
      "Training final model...\n",
      "Epoch 1/14\n",
      "\u001b[1m487/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7217 - loss: 0.5609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 22:33:23.962969: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "2025-06-30 22:33:24.245762: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1829', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - accuracy: 0.7219 - loss: 0.5608\n",
      "Epoch 2/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.4946\n",
      "Epoch 3/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7870 - loss: 0.4727\n",
      "Epoch 4/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.4595\n",
      "Epoch 5/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.4508\n",
      "Epoch 6/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4456\n",
      "Epoch 7/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4399\n",
      "Epoch 8/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8128 - loss: 0.4359\n",
      "Epoch 9/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.4321\n",
      "Epoch 10/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.4286\n",
      "Epoch 11/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.4268\n",
      "Epoch 12/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8164 - loss: 0.4238\n",
      "Epoch 13/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8182 - loss: 0.4205\n",
      "Epoch 14/14\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.4175\n",
      "\n",
      "Final Test Loss: 0.4295\n",
      "Final Test Accuracy: 0.8099\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Get the best hyperparameters from the study ---\n",
    "best_params = study.best_params\n",
    "\n",
    "# --- 2. Build the final model with the best hyperparameters ---\n",
    "final_model = build_model(best_params)\n",
    "final_model.summary()\n",
    "\n",
    "# --- 3. Determine the optimal number of epochs from the best trial ---\n",
    "# Get the history from the best trial\n",
    "best_trial_history = study.best_trial.user_attrs[\"history\"]\n",
    "# Find the epoch with the lowest validation loss\n",
    "optimal_epochs = np.argmin(best_trial_history['val_loss']) + 1\n",
    "print(f\"\\nOptimal number of epochs found: {optimal_epochs}\")\n",
    "\n",
    "# --- 4. Train the final model on the full training data for the optimal number of epochs ---\n",
    "print(\"Training final model...\")\n",
    "history = final_model.fit(\n",
    "    X_train_processed, y_train,\n",
    "    epochs=optimal_epochs, # Use the optimal number of epochs\n",
    "    batch_size=best_params.get('batch_size', 128), # Use batch size from params if available\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- 5. Evaluate the final model on the test set ---\n",
    "loss, accuracy = final_model.evaluate(X_test_processed, y_test, verbose=0)\n",
    "print(f\"\\nFinal Test Loss: {loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0083002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m488/488\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Final Test AUC Score: 0.8729\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 6. Calculate and Plot AUC ---\n",
    "\n",
    "# Get the predicted probabilities for the test set\n",
    "y_pred_proba = final_model.predict(X_test_processed).ravel()\n",
    "\n",
    "# Calculate the AUC score\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Final Test AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Calculate the ROC curve points\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cde79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
